{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4c4407",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-14T10:10:14.831571Z",
     "iopub.status.busy": "2025-02-14T10:10:14.831282Z",
     "iopub.status.idle": "2025-02-14T10:13:45.074737Z",
     "shell.execute_reply": "2025-02-14T10:13:45.073697Z"
    },
    "papermill": {
     "duration": 210.247975,
     "end_time": "2025-02-14T10:13:45.076271",
     "exception": false,
     "start_time": "2025-02-14T10:10:14.828296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and preprocessing completed.\n",
      "Log Loss: 0.0000\n",
      "Mean Absolute Error: 0.0000\n",
      "Brier Score: 0.0000\n",
      "Cross-validated MSE: 0.1885\n",
      "Submission file saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import glob                          # For file pattern matching\n",
    "import numpy as np                   # For numerical operations\n",
    "import pandas as pd                  # For data manipulation and analysis\n",
    "\n",
    "# Import scikit-learn modules for model building, evaluation, and preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, brier_score_loss\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.isotonic import IsotonicRegression  # For probability calibration\n",
    "\n",
    "import warnings\n",
    "# Suppress warnings to keep the output clean during runtime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class TournamentPredictor:\n",
    "    \"\"\"\n",
    "    Class to build, train, and generate predictions for the 2025 NCAA Basketball Tournaments.\n",
    "    \n",
    "    This class handles:\n",
    "    - Loading and preprocessing the data from CSV files.\n",
    "    - Creating useful features from the historical game data.\n",
    "    - Training a Random Forest model to predict game outcomes.\n",
    "    - Calibrating predicted probabilities using isotonic regression.\n",
    "    - Generating submission files in the required format.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "        Initialize the TournamentPredictor with the data path and preprocessing/model objects.\n",
    "        \n",
    "        Parameters:\n",
    "        - data_path: str, path pattern to the input CSV files (e.g., '/kaggle/input/march-machine-learning-mania-2025/**')\n",
    "        \"\"\"\n",
    "        self.data_path = data_path  # File path to input data files\n",
    "        self.data = None            # Dictionary to hold all loaded data files\n",
    "        self.teams = None           # Combined team information (men's and women's)\n",
    "        self.seeds = None           # Dictionary mapping season and team IDs to seed numbers\n",
    "        self.games = None           # DataFrame to hold combined game results (both season and tournament)\n",
    "        self.sub = None             # DataFrame for the submission file\n",
    "        self.gb = None              # Aggregated game statistics by team pairing\n",
    "        self.col = None             # List of feature column names used for training\n",
    "        \n",
    "        # Preprocessing objects:\n",
    "        # SimpleImputer: to fill in missing values (using mean strategy)\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "        # StandardScaler: to standardize features (mean=0, variance=1)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Create a Random Forest Regressor model with specific hyperparameters:\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=235,       # Number of trees in the forest\n",
    "            random_state=42,        # Seed for reproducibility\n",
    "            max_depth=15,           # Limit the depth of each tree to prevent overfitting\n",
    "            min_samples_split=2,    # Minimum number of samples required to split an internal node\n",
    "            max_features='auto'     # Use sqrt(n_features) for selecting features at each split\n",
    "        )\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load and preprocess all necessary data from CSV files.\n",
    "        \n",
    "        This method:\n",
    "        - Loads multiple CSV files from the specified directory.\n",
    "        - Combines data from both men's and women's teams.\n",
    "        - Processes team names, seeds, and game results.\n",
    "        - Creates various features and identifiers needed for model training and submission.\n",
    "        \"\"\"\n",
    "        # Find all CSV files matching the data path pattern\n",
    "        files = glob.glob(self.data_path)\n",
    "        \n",
    "        # Load each CSV file into a dictionary with keys based on the file name (without extension)\n",
    "        self.data = {\n",
    "            p.split('/')[-1].split('.')[0]: pd.read_csv(p, encoding='latin-1')\n",
    "            for p in files\n",
    "        }\n",
    "        \n",
    "        # Combine men's and women's team data into one DataFrame\n",
    "        teams = pd.concat([self.data['MTeams'], self.data['WTeams']])\n",
    "        # Combine team spellings for consistency\n",
    "        teams_spelling = pd.concat([self.data['MTeamSpellings'], self.data['WTeamSpellings']])\n",
    "        # Group by TeamID and count occurrences of team name spellings (could be used as a quality metric)\n",
    "        teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "        teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "        # Merge the teams data with the spellings count\n",
    "        self.teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "        # Delete temporary DataFrame to free memory\n",
    "        del teams_spelling\n",
    "        \n",
    "        # Combine season and tournament results for both compact and detailed formats\n",
    "        season_cresults = pd.concat([self.data['MRegularSeasonCompactResults'], self.data['WRegularSeasonCompactResults']])\n",
    "        season_dresults = pd.concat([self.data['MRegularSeasonDetailedResults'], self.data['WRegularSeasonDetailedResults']])\n",
    "        tourney_cresults = pd.concat([self.data['MNCAATourneyCompactResults'], self.data['WNCAATourneyCompactResults']])\n",
    "        tourney_dresults = pd.concat([self.data['MNCAATourneyDetailedResults'], self.data['WNCAATourneyDetailedResults']])\n",
    "        \n",
    "        # Load seeds data from both men's and women's tournaments\n",
    "        seeds_df = pd.concat([self.data['MNCAATourneySeeds'], self.data['WNCAATourneySeeds']])\n",
    "        # Also load game cities and seasons for potential future use\n",
    "        gcities = pd.concat([self.data['MGameCities'], self.data['WGameCities']])\n",
    "        seasons = pd.concat([self.data['MSeasons'], self.data['WSeasons']])\n",
    "        \n",
    "        # Create a dictionary for seeds with keys formatted as \"Season_TeamID\" and value as the seed number.\n",
    "        # The seed string in the CSV (e.g., \"W01\") has its first character removed to extract the numeric seed.\n",
    "        self.seeds = {\n",
    "            '_'.join(map(str, [int(k1), k2])): int(v[1:3])\n",
    "            for k1, v, k2 in seeds_df[['Season', 'Seed', 'TeamID']].values\n",
    "        }\n",
    "        \n",
    "        # Load additional data: cities and the sample submission file.\n",
    "        # The sample submission provides the template for the final predictions.\n",
    "        cities = self.data['Cities']\n",
    "        self.sub = self.data['SampleSubmissionStage1']\n",
    "        # Free up memory by deleting unused variables\n",
    "        del seeds_df, cities\n",
    "        \n",
    "        # Mark the type of results: 'S' for season games and 'T' for tournament games\n",
    "        season_cresults['ST'] = 'S'\n",
    "        season_dresults['ST'] = 'S'\n",
    "        tourney_cresults['ST'] = 'T'\n",
    "        tourney_dresults['ST'] = 'T'\n",
    "        \n",
    "        # We are using the detailed results for feature processing\n",
    "        self.games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "        # Reset index for consistency\n",
    "        self.games.reset_index(drop=True, inplace=True)\n",
    "        # Map the location column 'WLoc' to numerical values (A=1, H=2, N=3)\n",
    "        self.games['WLoc'] = self.games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "        \n",
    "        # Create unique IDs for each game and extract team identifiers\n",
    "        # ID is created by concatenating Season and the sorted team IDs\n",
    "        self.games['ID'] = self.games.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Season']] + sorted([r['WTeamID'], r['LTeamID']]))), axis=1\n",
    "        )\n",
    "        # Create an ID based solely on team IDs (regardless of season)\n",
    "        self.games['IDTeams'] = self.games.apply(\n",
    "            lambda r: '_'.join(map(str, sorted([r['WTeamID'], r['LTeamID']]))), axis=1\n",
    "        )\n",
    "        # Define Team1 as the team with the lower team ID and Team2 as the other team\n",
    "        self.games['Team1'] = self.games.apply(\n",
    "            lambda r: sorted([r['WTeamID'], r['LTeamID']])[0], axis=1\n",
    "        )\n",
    "        self.games['Team2'] = self.games.apply(\n",
    "            lambda r: sorted([r['WTeamID'], r['LTeamID']])[1], axis=1\n",
    "        )\n",
    "        # Create IDs that include season information for each team (for mapping seeds)\n",
    "        self.games['IDTeam1'] = self.games.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1\n",
    "        )\n",
    "        self.games['IDTeam2'] = self.games.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1\n",
    "        )\n",
    "        # Map seeds to teams using the precomputed dictionary; if missing, fill with 0\n",
    "        self.games['Team1Seed'] = self.games['IDTeam1'].map(self.seeds).fillna(0)\n",
    "        self.games['Team2Seed'] = self.games['IDTeam2'].map(self.seeds).fillna(0)\n",
    "        \n",
    "        # Create additional game-level features:\n",
    "        # - Score difference between winning and losing teams\n",
    "        self.games['ScoreDiff'] = self.games['WScore'] - self.games['LScore']\n",
    "        # - Binary indicator for whether the team with the lower TeamID (Team1) won the game\n",
    "        self.games['Pred'] = self.games.apply(\n",
    "            lambda r: 1.0 if sorted([r['WTeamID'], r['LTeamID']])[0] == r['WTeamID'] else 0.0, axis=1\n",
    "        )\n",
    "        # Normalize score difference so that it is positive when Team1 wins\n",
    "        self.games['ScoreDiffNorm'] = self.games.apply(\n",
    "            lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0.0 else r['ScoreDiff'], axis=1\n",
    "        )\n",
    "        # Compute the difference in seeds between Team1 and Team2\n",
    "        self.games['SeedDiff'] = self.games['Team1Seed'] - self.games['Team2Seed']\n",
    "        # Replace any remaining missing values with -1\n",
    "        self.games = self.games.fillna(-1)\n",
    "        \n",
    "        # ------------------------\n",
    "        # Aggregate game statistics for each team pairing.\n",
    "        # For a list of columns capturing various game stats:\n",
    "        c_score_col = [\n",
    "            'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', \n",
    "            'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', \n",
    "            'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'\n",
    "        ]\n",
    "        # Define aggregation functions to be applied on each of these columns\n",
    "        c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "        # Group by team pairing (IDTeams) and aggregate the statistics\n",
    "        self.gb = self.games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "        # Rename aggregated columns to have a suffix indicating they belong to aggregated game statistics\n",
    "        self.gb.columns = [''.join(c) + '_c_score' for c in self.gb.columns]\n",
    "        \n",
    "        # Filter the games DataFrame to keep only tournament games (where ST is 'T')\n",
    "        self.games = self.games[self.games['ST'] == 'T']\n",
    "        \n",
    "        # ------------------------\n",
    "        # Process the submission file which provides the template for predictions:\n",
    "        # - Set a default location value (3, representing 'Neutral')\n",
    "        self.sub['WLoc'] = 3\n",
    "        # - Extract the season from the submission ID (first part before the underscore)\n",
    "        self.sub['Season'] = self.sub['ID'].map(lambda x: x.split('_')[0]).astype(int)\n",
    "        # - Extract Team1 and Team2 from the submission ID (second and third parts)\n",
    "        self.sub['Team1'] = self.sub['ID'].map(lambda x: x.split('_')[1])\n",
    "        self.sub['Team2'] = self.sub['ID'].map(lambda x: x.split('_')[2])\n",
    "        # Create a combined ID for teams similar to the games DataFrame\n",
    "        self.sub['IDTeams'] = self.sub.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1\n",
    "        )\n",
    "        # Create season-specific IDs for each team for seed mapping\n",
    "        self.sub['IDTeam1'] = self.sub.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1\n",
    "        )\n",
    "        self.sub['IDTeam2'] = self.sub.apply(\n",
    "            lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1\n",
    "        )\n",
    "        # Map seed values to teams; if not found, use 0 as default\n",
    "        self.sub['Team1Seed'] = self.sub['IDTeam1'].map(self.seeds).fillna(0)\n",
    "        self.sub['Team2Seed'] = self.sub['IDTeam2'].map(self.seeds).fillna(0)\n",
    "        # Calculate seed difference for the matchup\n",
    "        self.sub['SeedDiff'] = self.sub['Team1Seed'] - self.sub['Team2Seed']\n",
    "        # Replace any missing values in the submission DataFrame with -1\n",
    "        self.sub = self.sub.fillna(-1)\n",
    "        \n",
    "        # Merge the aggregated game statistics into both the games and submission DataFrames.\n",
    "        # This step adds historical matchup statistics as features for prediction.\n",
    "        self.games = pd.merge(self.games, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "        self.sub = pd.merge(self.sub, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "        \n",
    "        # Define the list of feature columns to use for training.\n",
    "        # Exclude columns that are identifiers or raw scores which are not used as features.\n",
    "        exclude_cols = [\n",
    "            'ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2',\n",
    "            'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', \n",
    "            'ScoreDiffNorm', 'WLoc'\n",
    "        ] + c_score_col\n",
    "        self.col = [c for c in self.games.columns if c not in exclude_cols]\n",
    "        \n",
    "        print(\"Data loading and preprocessing completed.\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Train the Random Forest model using the tournament games data.\n",
    "        \n",
    "        This method:\n",
    "        - Prepares the training features and target variable.\n",
    "        - Applies imputation and scaling.\n",
    "        - Fits the Random Forest model.\n",
    "        - Calibrates the predicted probabilities using Isotonic Regression.\n",
    "        - Prints evaluation metrics such as Log Loss, MAE, Brier Score, and cross-validated MSE.\n",
    "        \"\"\"\n",
    "        # Select the training features from the games DataFrame and fill missing values with -1\n",
    "        X = self.games[self.col].fillna(-1)\n",
    "        # Apply imputation (fill missing values) based on the training data's mean\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "        # Scale the features to standardize them (mean=0, variance=1)\n",
    "        X_scaled = self.scaler.fit_transform(X_imputed)\n",
    "        # Target variable: whether the team with the lower TeamID (Team1) won the game\n",
    "        y = self.games['Pred']\n",
    "        \n",
    "        # Fit the Random Forest model on the preprocessed features\n",
    "        self.model.fit(X_scaled, y)\n",
    "        # Predict on the training set and clip predictions to avoid extreme probabilities\n",
    "        pred = self.model.predict(X_scaled).clip(0.001, 0.999)\n",
    "        \n",
    "        # ---- Calibration Step ----\n",
    "        # Use Isotonic Regression to calibrate the predicted probabilities.\n",
    "        # Note: Ideally, calibration should be performed on a separate holdout set.\n",
    "        ir = IsotonicRegression(out_of_bounds='clip')\n",
    "        ir.fit(pred, y)  # Fit the calibration model using predictions and true labels\n",
    "        pred_cal = ir.transform(pred)  # Transform the predictions\n",
    "        \n",
    "        # Calculate and print various evaluation metrics:\n",
    "        print(f'Log Loss: {log_loss(y, pred_cal):.4f}')\n",
    "        print(f'Mean Absolute Error: {mean_absolute_error(y, pred_cal):.4f}')\n",
    "        print(f'Brier Score: {brier_score_loss(y, pred_cal):.4f}')\n",
    "        # Use cross-validation to evaluate model performance (MSE metric)\n",
    "        cv_scores = cross_val_score(self.model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "        print(f'Cross-validated MSE: {-cv_scores.mean():.4f}')\n",
    "\n",
    "    def predict_submission(self, output_file='submission.csv'):\n",
    "        \"\"\"\n",
    "        Generate predictions for the submission file and save the results to a CSV file.\n",
    "        \n",
    "        This method:\n",
    "        - Prepares the submission features.\n",
    "        - Applies the same imputation and scaling as used in training.\n",
    "        - Generates predictions and calibrates them using Isotonic Regression.\n",
    "        - Writes the final predictions to the specified CSV file.\n",
    "        \n",
    "        Parameters:\n",
    "        - output_file: str, file name for the output submission CSV (default: 'submission.csv')\n",
    "        \"\"\"\n",
    "        # Prepare submission features and fill missing values\n",
    "        sub_X = self.sub[self.col].fillna(-1)\n",
    "        # Apply the imputer (using the training data statistics)\n",
    "        sub_X_imputed = self.imputer.transform(sub_X)\n",
    "        # Scale the submission features using the previously fitted scaler\n",
    "        sub_X_scaled = self.scaler.transform(sub_X_imputed)\n",
    "        # Predict probabilities using the trained model and clip the values to a reasonable range\n",
    "        preds = self.model.predict(sub_X_scaled).clip(0.01, 0.99)\n",
    "        \n",
    "        # ---- Calibration for Submission Predictions ----\n",
    "        # Refit the isotonic regression on the training data predictions for consistency.\n",
    "        ir = IsotonicRegression(out_of_bounds='clip')\n",
    "        # Prepare training features again for calibration purposes\n",
    "        X_train = self.imputer.fit_transform(self.games[self.col].fillna(-1))\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        # Get predictions on the training set\n",
    "        train_preds = self.model.predict(X_train_scaled).clip(0.001, 0.999)\n",
    "        # Fit the isotonic regression model using training predictions and true labels\n",
    "        ir.fit(train_preds, self.games['Pred'])\n",
    "        # Calibrate the submission predictions\n",
    "        preds_cal = ir.transform(preds)\n",
    "        \n",
    "        # Assign calibrated predictions to the submission DataFrame\n",
    "        self.sub['Pred'] = preds_cal\n",
    "        # Save the submission file with only the required columns (ID and Pred)\n",
    "        self.sub[['ID', 'Pred']].to_csv(output_file, index=False)\n",
    "        print(f\"Submission file saved to {output_file}\")\n",
    "\n",
    "    def run_all(self):\n",
    "        \"\"\"\n",
    "        Run the complete pipeline:\n",
    "        1. Load and preprocess data.\n",
    "        2. Train the model.\n",
    "        3. Generate submission predictions and save them to a file.\n",
    "        \"\"\"\n",
    "        self.load_data()\n",
    "        self.train_model()\n",
    "        self.predict_submission()\n",
    "\n",
    "# ------------------------\n",
    "# Main block: Execute the full pipeline if this script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the data path (adjust the path as needed for your environment)\n",
    "    data_path = '/kaggle/input/march-machine-learning-mania-2025/**'\n",
    "    # Initialize the predictor with the data path\n",
    "    predictor = TournamentPredictor(data_path)\n",
    "    # Run the full pipeline: data loading, training, and prediction generation\n",
    "    predictor.run_all()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11018643,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 213.815549,
   "end_time": "2025-02-14T10:13:45.696688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-14T10:10:11.881139",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
