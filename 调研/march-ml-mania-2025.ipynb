{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4541ff18",
   "metadata": {
    "papermill": {
     "duration": 0.003582,
     "end_time": "2025-03-03T19:18:16.913667",
     "exception": false,
     "start_time": "2025-03-03T19:18:16.910085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Notes\n",
    "\n",
    "- I know nothing about Basketball so let's see how this goes\n",
    "- The feature engineering seriously needs to be worked on\n",
    "- Seeds do not change during the season\n",
    "- Predict the probability of the lower TeamID winning\n",
    "- Only rely on given data (just to make it easier)\n",
    "- Possibly make a df for team statistics throughout the years (like if a team has been has been active since 1990, you do 1 row for that team per year). If you do this, make a separate df for women.\n",
    "- Possibly make a df that's just for games where it shows who won.\n",
    "- Somehow combine these into something a model can use to train on? This I need to think a lot about. If I have 3 different dataframes, with each giving me different kinds of data, how do I make a ML model that can train on those and predict the mashups of March Madness in the correct format?\n",
    "- Because of the last bullet, try to not do any feature engineering or creating dataframes until you think about how a model can use it.\n",
    "- After making dataframes, check dtypes\n",
    "\n",
    "# Current game plan for features to attempt\n",
    "\n",
    "### MTeams and WTeams\n",
    "- **TeamID:** this is the unique team ID (does not repeat in this csv)\n",
    "  - 4 digit number\n",
    "- **TeamName:** short spelling of the team's name. this can be good just for a reference (not for prediction)\n",
    "  - 16 character name\n",
    "- **FirstD1Season:** the year that they became D1. these start at 1985\n",
    "  - 4 digit number (1985-2025)\n",
    "- **LastD1Season:** the last year they were D1.\n",
    "  - 4 digit number (1985-2025)\n",
    "\n",
    "### MNCAATourneySeeds and WNCAATourneySeeds\n",
    "- **Season:** year of the season\n",
    "  - 4 digit number (1985-2024)\n",
    "- **Seed:** seed of the team\n",
    "  - last 2 characters are the seed\n",
    "- **TeamID:** team id of the season and seed\n",
    "  - 4 digit number\n",
    "\n",
    "### MNCAATourneySlots and WNCAATourneySlots\n",
    "- **Season:** year of season\n",
    "  - 4 digit number (1985-2024)\n",
    "- **Slot:** slot that gives information on the seed from the winning or favored team\n",
    "  - for play-ins, it is a 3 character string where the last 2 numbers are the winning seed. for regular tournaments, it is a 4 character string where the second character tells you the round, and the last character (or 2) tells you the expected seed of the favored team\n",
    "- **StrongSeed:** seed that's strong\n",
    "  - last 2 characters are the seed\n",
    "- **WeakSeed:** weaker seed\n",
    "  - last 2 characters are the seed\n",
    "\n",
    "### MRegularSeasonDetailedResults and WRegularSeasonDetailedResults\n",
    "- **Season:** year of the season\n",
    "  - 4 digit number (2023-2025)\n",
    "- **DayNum**: higher the number, the better the team is because they lasted longer\n",
    "  - number\n",
    "- **WTeamID:** winning team id\n",
    "  - 4 digit number\n",
    "- **WScore:** winning score\n",
    "  - number\n",
    "- **LTeamID:** losting team id\n",
    "  - 4 digit number\n",
    "- **LScore:** losing score\n",
    "  - number\n",
    "- **WLoc:** location of winning team\n",
    "  - character (H, A, or N)\n",
    "- **NumOT:** number of overtime periods\n",
    "  - number\n",
    "- **WFGM:** field goals made by winning team\n",
    "  - number\n",
    "\n",
    "- **OOPS! There are way more columns that are good, I just didn't see them before. Use them all...**\n",
    "\n",
    "### MNCAATourneyDetailedResults and WNCAATourneyDetailedResults\n",
    "- same as (M/W)RegularSeasonDetailedResults\n",
    "\n",
    "### MSecondaryTourneyTeams and WSecondaryTournamentTeams\n",
    "- **Season:** year\n",
    "  - 4 digit number (1985-2024)\n",
    "- **SecondaryTourney:** abbreviation of tournament\n",
    "  - 3 characters\n",
    "- **TeamID:** team that played in it\n",
    "  - 4 digit number\n",
    "\n",
    "### MSecondaryTourneyCompactResults and WSecondaryTourneyCompactResults\n",
    "- all of this is the same as (M/W)RegularSeasonDetailedResults except there is no WFGM and instead it has the SecondaryTourney column and no team box scores\n",
    "\n",
    "### Cities\n",
    "- **CityID:** unique city id\n",
    "  - number\n",
    "- **State:** state abbreviation\n",
    "  - 2 characters\n",
    "\n",
    "### MGameCities and WGameCities\n",
    "- **Season:** year\n",
    "  - 4 digit number (2010-2025)\n",
    "- **DayNum**: higher is better\n",
    "  - number\n",
    "- **WTeamID:** winning team\n",
    "  - 4 digit number\n",
    "- **LTeamID:** losing team\n",
    "  - 4 digit number\n",
    "- **CRType:** says whether the game is regular, ncaa, or secondary\n",
    "  - characters\n",
    "- **CityID:** unique city id\n",
    "  - 4 digit number\n",
    "\n",
    "### Other features to possibly make\n",
    "- Win/lose ratio (for each team)\n",
    "- Score of left team - score of right team difference (for that game)\n",
    "- Calculate ELO rating per team\n",
    "\n",
    "### Target\n",
    "- I think a good target would be to make it so if each row is for 2 competing teams, show a 1 if the left team won, and a 0 if they lost. Then, the ML model will predict this and show a probability for it.\n",
    "- I saw someone did it where instead of it being a 1 if they actually won, they did it so that the smaller TeamID is 1 and the other is 0. Not sure which route to go.\n",
    "\n",
    "\n",
    "- Actually, maybe just make it into 1 df.\n",
    "\n",
    "### Dataframe Structure\n",
    "- **ID:** of team mashup (YYYY_T1ID_T2ID) from SampleSubmissionStage1\n",
    "- **Year:** YYYY taken from SampleSubmissionStage1\n",
    "\n",
    "- **LTeam:** taken from SampleSubmissionStage1\n",
    "- **LTeamName:** taken from TeamName from (M/W)Teams (just to see team name, not for training)\n",
    "\n",
    "- **RTeam:** taken from SampleSubmissionStage1\n",
    "- **RTeamName:** taken from TeamName from (M/W)Teams (just to see team name, not for training)\n",
    "\n",
    "- **D1Diff:** taken from subtracting the left LastD1Season - FirstD1Season from the right from (M/W)Teams\n",
    "- **SeedDiff:** taken from MNCAATourneySeeds from subtracting the left seed from the right\n",
    "- **FavoredSeed:** taken from MNCAATourneySlots where it's 1 if the left team is the favored seed (if it's all 1 then remove this)\n",
    "\n",
    "- **RegELODiff:** which uses the data from (M/W)RegularSeasonDetailedResults to calculate the difference in ELO\n",
    "- **TourneyELODiff:** which uses the data from (M/W)NCAATourneyDetailedResults to calculate the difference in ELO\n",
    "\n",
    "- **Pred:** where 1 is if the left team won the game or 0 if they didn't.\n",
    "\n",
    "# WHAT?????????????\n",
    "- Please review all of the code and figure out exactly how the feature selection works\n",
    "- why are you clipping predictions\n",
    "- why use a regressor instead of a classifier\n",
    "- why are missing values filled with -1\n",
    "- is the standard scaler scaling any categorical columns??\n",
    "- why are we fitting on X and then predicting with X? is this not the same as fitting with training data and then predicting with training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc6350f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:16.920431Z",
     "iopub.status.busy": "2025-03-03T19:18:16.920224Z",
     "iopub.status.idle": "2025-03-03T19:18:19.122068Z",
     "shell.execute_reply": "2025-03-03T19:18:19.121350Z"
    },
    "papermill": {
     "duration": 2.206816,
     "end_time": "2025-03-03T19:18:19.123613",
     "exception": false,
     "start_time": "2025-03-03T19:18:16.916797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd # I wanted to use fireducks instead, but it was giving me issues\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import brier_score_loss, log_loss, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f6ab7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:19.130923Z",
     "iopub.status.busy": "2025-03-03T19:18:19.130561Z",
     "iopub.status.idle": "2025-03-03T19:18:24.105181Z",
     "shell.execute_reply": "2025-03-03T19:18:24.104248Z"
    },
    "papermill": {
     "duration": 4.979957,
     "end_time": "2025-03-03T19:18:24.106884",
     "exception": false,
     "start_time": "2025-03-03T19:18:19.126927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting all files\n",
    "path = \"/kaggle/input/march-machine-learning-mania-2025/**\"\n",
    "data = {p.split('/')[-1].split('.')[0] : pd.read_csv(p, encoding='latin-1') for p in glob.glob(path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1148610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:24.114343Z",
     "iopub.status.busy": "2025-03-03T19:18:24.114090Z",
     "iopub.status.idle": "2025-03-03T19:18:24.117810Z",
     "shell.execute_reply": "2025-03-03T19:18:24.117019Z"
    },
    "papermill": {
     "duration": 0.008619,
     "end_time": "2025-03-03T19:18:24.118961",
     "exception": false,
     "start_time": "2025-03-03T19:18:24.110342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\"\"\"\n",
    "MTeams = data[\"MTeams\"]\n",
    "WTeams = data[\"WTeams\"]\n",
    "\n",
    "MNCAATourneySeeds = data[\"MNCAATourneySeeds\"]\n",
    "WNCAATourneySeeds = data[\"WNCAATourneySeeds\"]\n",
    "\n",
    "MNCAATourneySlots = data[\"MNCAATourneySlots\"]\n",
    "WNCAATourneySlots = data[\"WNCAATourneySlots\"]\n",
    "\n",
    "MRegularSeasonDetailedResults = data[\"MRegularSeasonDetailedResults\"]\n",
    "WRegularSeasonDetailedResults = data[\"WRegularSeasonDetailedResults\"]\n",
    "\n",
    "MNCAATourneyDetailedResults = data[\"MNCAATourneyDetailedResults\"]\n",
    "WNCAATourneyDetailedResults = data[\"WNCAATourneyDetailedResults\"]\n",
    "\n",
    "MSecondaryTourneyTeams = data[\"MSecondaryTourneyTeams\"]\n",
    "WSecondaryTourneyTeams = data[\"WSecondaryTourneyTeams\"]\n",
    "\n",
    "MSecondaryTourneyCompactResults = data[\"MSecondaryTourneyCompactResults\"]\n",
    "WSecondaryTourneyCompactResults = data[\"WSecondaryTourneyCompactResults\"]\n",
    "\n",
    "Cities = data[\"Cities\"]\n",
    "\n",
    "MGameCities = data[\"MGameCities\"]\n",
    "WGameCities = data[\"WGameCities\"]\n",
    "\"\"\"\n",
    "\n",
    "# To be used for storing data, and later to take the IDs\n",
    "df = data[\"SampleSubmissionStage2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf2ca2",
   "metadata": {
    "papermill": {
     "duration": 0.002837,
     "end_time": "2025-03-03T19:18:24.124915",
     "exception": false,
     "start_time": "2025-03-03T19:18:24.122078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed532503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:24.131388Z",
     "iopub.status.busy": "2025-03-03T19:18:24.131155Z",
     "iopub.status.idle": "2025-03-03T19:18:24.135960Z",
     "shell.execute_reply": "2025-03-03T19:18:24.135244Z"
    },
    "papermill": {
     "duration": 0.009442,
     "end_time": "2025-03-03T19:18:24.137209",
     "exception": false,
     "start_time": "2025-03-03T19:18:24.127767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['Year'] = [int(yr[0:4]) for yr in df['ID']]\\ndf['LTeam'] = [int(L[5:9]) for L in df['ID']]\\ndf['RTeam'] = [int(R[10:14]) for R in df['ID']]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating year, left team, and right team columns\n",
    "\"\"\"\n",
    "df['Year'] = [int(yr[0:4]) for yr in df['ID']]\n",
    "df['LTeam'] = [int(L[5:9]) for L in df['ID']]\n",
    "df['RTeam'] = [int(R[10:14]) for R in df['ID']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d22f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:24.144316Z",
     "iopub.status.busy": "2025-03-03T19:18:24.144066Z",
     "iopub.status.idle": "2025-03-03T19:18:43.557929Z",
     "shell.execute_reply": "2025-03-03T19:18:43.557260Z"
    },
    "papermill": {
     "duration": 19.419105,
     "end_time": "2025-03-03T19:18:43.559384",
     "exception": false,
     "start_time": "2025-03-03T19:18:24.140279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lots of feature selecting and engineering\n",
    "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "del teams_spelling\n",
    "\n",
    "season_cresults = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']])\n",
    "season_dresults = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']])\n",
    "tourney_cresults = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']])\n",
    "tourney_dresults = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']])\n",
    "slots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\n",
    "seeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "gcities = pd.concat([data['MGameCities'], data['WGameCities']])\n",
    "seasons = pd.concat([data['MSeasons'], data['WSeasons']])\n",
    "\n",
    "seeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\n",
    "cities = data['Cities']\n",
    "sub = data['SampleSubmissionStage2']\n",
    "del data\n",
    "\n",
    "season_cresults['ST'] = 'S'\n",
    "season_dresults['ST'] = 'S'\n",
    "tourney_cresults['ST'] = 'T'\n",
    "tourney_dresults['ST'] = 'T'\n",
    "games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "games.reset_index(drop=True, inplace=True)\n",
    "games['WLoc'] = games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "games['ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "games['IDTeams'] = games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "games['Team1'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "games['Team2'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "games['IDTeam1'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "games['IDTeam2'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "\n",
    "games['Team1Seed'] = games['IDTeam1'].map(seeds).fillna(0)\n",
    "games['Team2Seed'] = games['IDTeam2'].map(seeds).fillna(0)\n",
    "\n",
    "games['ScoreDiff'] = games['WScore'] - games['LScore']\n",
    "games['Pred'] = games.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "games['ScoreDiffNorm'] = games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "games['SeedDiff'] = games['Team1Seed'] - games['Team2Seed']\n",
    "games = games.fillna(-1)\n",
    "\n",
    "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n",
    " 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n",
    " 'LBlk', 'LPF']\n",
    "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "gb = games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n",
    "\n",
    "games = games[games['ST']=='T']\n",
    "\n",
    "sub['WLoc'] = 3\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['Season'].astype(int)\n",
    "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
    "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
    "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
    "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
    "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed']\n",
    "sub = sub.fillna(-1)\n",
    "\n",
    "games = pd.merge(games, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "\n",
    "col = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2',\n",
    "                                             'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm',\n",
    "                                             'WLoc'] + c_score_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7455980",
   "metadata": {
    "papermill": {
     "duration": 0.002964,
     "end_time": "2025-03-03T19:18:43.565804",
     "exception": false,
     "start_time": "2025-03-03T19:18:43.562840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b782809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:43.572545Z",
     "iopub.status.busy": "2025-03-03T19:18:43.572325Z",
     "iopub.status.idle": "2025-03-03T19:18:43.888804Z",
     "shell.execute_reply": "2025-03-03T19:18:43.888113Z"
    },
    "papermill": {
     "duration": 0.321752,
     "end_time": "2025-03-03T19:18:43.890498",
     "exception": false,
     "start_time": "2025-03-03T19:18:43.568746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting training data\n",
    "X = games[col].fillna(-1)\n",
    "sub_X = sub[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8486209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:43.898212Z",
     "iopub.status.busy": "2025-03-03T19:18:43.897901Z",
     "iopub.status.idle": "2025-03-03T19:18:43.900846Z",
     "shell.execute_reply": "2025-03-03T19:18:43.900246Z"
    },
    "papermill": {
     "duration": 0.008265,
     "end_time": "2025-03-03T19:18:43.902213",
     "exception": false,
     "start_time": "2025-03-03T19:18:43.893948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# Do some grid search here for the parameters\n",
    "# After doing the grid search, save the best parameters and create the param_grid in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2cf9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:18:43.909049Z",
     "iopub.status.busy": "2025-03-03T19:18:43.908842Z",
     "iopub.status.idle": "2025-03-03T19:20:00.445344Z",
     "shell.execute_reply": "2025-03-03T19:20:00.444612Z"
    },
    "papermill": {
     "duration": 76.54177,
     "end_time": "2025-03-03T19:20:00.447083",
     "exception": false,
     "start_time": "2025-03-03T19:18:43.905313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [19:18:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# XGB parameters\n",
    "param_grid = {\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 6\n",
    "}\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBRegressor(**param_grid, device=\"gpu\", random_state=42))\n",
    "])\n",
    "\n",
    "# Fitting pipeline\n",
    "pipeline.fit(X, games['Pred'])\n",
    "\n",
    "# Predicting games and submissions\n",
    "pred = pipeline.predict(X).clip(0.001, 0.999)\n",
    "sub_pred = pipeline.predict(sub_X).clip(0.001, 0.999)\n",
    "\n",
    "# Cross validation (for the MSE)\n",
    "cv_scores = cross_val_score(pipeline, X, games['Pred'], cv=5, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781da94",
   "metadata": {
    "papermill": {
     "duration": 0.003008,
     "end_time": "2025-03-03T19:20:00.453757",
     "exception": false,
     "start_time": "2025-03-03T19:20:00.450749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6eceb6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:20:00.460576Z",
     "iopub.status.busy": "2025-03-03T19:20:00.460324Z",
     "iopub.status.idle": "2025-03-03T19:20:00.471570Z",
     "shell.execute_reply": "2025-03-03T19:20:00.470830Z"
    },
    "papermill": {
     "duration": 0.016141,
     "end_time": "2025-03-03T19:20:00.472904",
     "exception": false,
     "start_time": "2025-03-03T19:20:00.456763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.00163\n",
      "Mean Absolute Error: 0.00163\n",
      "Brier Score: 0.00001\n",
      "Cross-validated MSE: 0.20514\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Log Loss: {log_loss(games[\"Pred\"], pred):.5f}')\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(games[\"Pred\"], pred):.5f}')\n",
    "print(f'Brier Score: {brier_score_loss(games[\"Pred\"], pred):.5f}')\n",
    "print(f'Cross-validated MSE: {-cv_scores.mean():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3e510",
   "metadata": {
    "papermill": {
     "duration": 0.003088,
     "end_time": "2025-03-03T19:20:00.479299",
     "exception": false,
     "start_time": "2025-03-03T19:20:00.476211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1511e197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T19:20:00.486718Z",
     "iopub.status.busy": "2025-03-03T19:20:00.486477Z",
     "iopub.status.idle": "2025-03-03T19:20:00.698498Z",
     "shell.execute_reply": "2025-03-03T19:20:00.697613Z"
    },
    "papermill": {
     "duration": 0.217232,
     "end_time": "2025-03-03T19:20:00.699830",
     "exception": false,
     "start_time": "2025-03-03T19:20:00.482598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131407, 2) \n",
      "\n",
      "            ID     Pred\n",
      "2025_1101_1102 0.436362\n",
      "2025_1101_1103 0.293444\n",
      "2025_1101_1104 0.293444\n",
      "2025_1101_1105 0.293444\n",
      "2025_1101_1106 0.293444 \n",
      "\n",
      "            ID     Pred\n",
      "2025_3477_3479 0.293444\n",
      "2025_3477_3480 0.293444\n",
      "2025_3478_3479 0.488614\n",
      "2025_3478_3480 0.293444\n",
      "2025_3479_3480 0.293444\n",
      "\n",
      "Submission file saved! Good luck!!! :)\n"
     ]
    }
   ],
   "source": [
    "# Creating submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': df['ID'],\n",
    "    'Pred': sub_pred\n",
    "})\n",
    "\n",
    "# Shape and head/tail of submission\n",
    "print(f\"{submission_df.shape} \\n\")\n",
    "print(f\"{submission_df.head().to_string(index=False)} \\n\")\n",
    "print(submission_df.tail().to_string(index=False))\n",
    "\n",
    "# Saving to csv\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file saved! Good luck!!! :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e2609",
   "metadata": {
    "papermill": {
     "duration": 0.003093,
     "end_time": "2025-03-03T19:20:00.706459",
     "exception": false,
     "start_time": "2025-03-03T19:20:00.703366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .README\n",
    "\n",
    "## About the Notebook\n",
    "\n",
    "\n",
    "\n",
    "## About the Data\n",
    "\n",
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "\n",
    "\n",
    "## Thought Process\n",
    "\n",
    " (####)\n",
    "\n",
    "## What I Learned\n",
    "\n",
    "\n",
    "\n",
    "## Future Endeavors\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11165145,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.000645,
   "end_time": "2025-03-03T19:20:01.327689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-03T19:18:14.327044",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
