{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff50d25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:07.820215Z",
     "iopub.status.busy": "2025-03-03T08:40:07.819756Z",
     "iopub.status.idle": "2025-03-03T08:40:08.899368Z",
     "shell.execute_reply": "2025-03-03T08:40:08.898119Z"
    },
    "papermill": {
     "duration": 1.096001,
     "end_time": "2025-03-03T08:40:08.901814",
     "exception": false,
     "start_time": "2025-03-03T08:40:07.805813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd20b0f",
   "metadata": {
    "papermill": {
     "duration": 0.010681,
     "end_time": "2025-03-03T08:40:08.924125",
     "exception": false,
     "start_time": "2025-03-03T08:40:08.913444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stage 1: Analyze men's match data and create a prediction model for men's teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e0a63",
   "metadata": {
    "papermill": {
     "duration": 0.010332,
     "end_time": "2025-03-03T08:40:08.945714",
     "exception": false,
     "start_time": "2025-03-03T08:40:08.935382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating the winning rate for each team in the men's conference Tourney games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb45f4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:08.969080Z",
     "iopub.status.busy": "2025-03-03T08:40:08.968479Z",
     "iopub.status.idle": "2025-03-03T08:40:09.056850Z",
     "shell.execute_reply": "2025-03-03T08:40:09.055270Z"
    },
    "papermill": {
     "duration": 0.102424,
     "end_time": "2025-03-03T08:40:09.058980",
     "exception": false,
     "start_time": "2025-03-03T08:40:08.956556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conference tournament summary preview:\n",
      "   TeamID  TotalGames  ConferenceWins  TeamConferenceWinRate  \\\n",
      "0    1101          10               7               0.700000   \n",
      "1    1102          30               6               0.200000   \n",
      "2    1103          56              38               0.678571   \n",
      "3    1104          44              23               0.522727   \n",
      "4    1105          28              12               0.428571   \n",
      "\n",
      "   IsConferenceTourney  \n",
      "0                    1  \n",
      "1                    1  \n",
      "2                    1  \n",
      "3                    1  \n",
      "4                    1  \n"
     ]
    }
   ],
   "source": [
    "# Load conference tournament match data\n",
    "conference_games = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MConferenceTourneyGames.csv')\n",
    "\n",
    "# Convert match results into a format where each team has its own record\n",
    "# Create a DataFrame for winning teams with a win label\n",
    "conference_games_wins = conference_games[['WTeamID']].copy()\n",
    "conference_games_wins['Win'] = 1\n",
    "conference_games_wins.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Create a DataFrame for losing teams with a loss label\n",
    "conference_games_losses = conference_games[['LTeamID']].copy()\n",
    "conference_games_losses['Win'] = 0\n",
    "conference_games_losses.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Combine both DataFrames to create a unified match record per team\n",
    "conference_team_stats = pd.concat([conference_games_wins, conference_games_losses], ignore_index=True)\n",
    "\n",
    "# Calculate total matches played and win rate for each team in conference tournaments\n",
    "conference_summary = (\n",
    "    conference_team_stats.groupby('TeamID')\n",
    "    .agg(TotalGames=('Win', 'count'), ConferenceWins=('Win', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute win rate in conference tournaments\n",
    "conference_summary['TeamConferenceWinRate'] = (\n",
    "    conference_summary['ConferenceWins'] / conference_summary['TotalGames']\n",
    ")\n",
    "\n",
    "# Add an indicator feature to specify that this data is from a conference tournament\n",
    "conference_summary['IsConferenceTourney'] = 1\n",
    "\n",
    "# Save the processed conference tournament feature data\n",
    "conference_summary.to_csv('/kaggle/working/conference_summary.csv', index=False)\n",
    "\n",
    "# Display a preview of the processed data\n",
    "print(\"Conference tournament summary preview:\")\n",
    "print(conference_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4ed28",
   "metadata": {
    "papermill": {
     "duration": 0.010301,
     "end_time": "2025-03-03T08:40:09.080146",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.069845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate the winning rate for each team and the average point difference in the tournament under pressure for men:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7665e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:09.104641Z",
     "iopub.status.busy": "2025-03-03T08:40:09.104286Z",
     "iopub.status.idle": "2025-03-03T08:40:09.157200Z",
     "shell.execute_reply": "2025-03-03T08:40:09.155768Z"
    },
    "papermill": {
     "duration": 0.067866,
     "end_time": "2025-03-03T08:40:09.159511",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.091645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tournament features preview:\n",
      "   TeamID  TournamentWinRate  AvgTournamentScoreDiff\n",
      "0    1101           0.333333                1.000000\n",
      "1    1102           0.000000                0.000000\n",
      "2    1103           0.000000                0.000000\n",
      "3    1104           0.574468               10.555556\n",
      "4    1105           0.000000                0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load tournament match data\n",
    "tourney_results = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyCompactResults.csv')\n",
    "\n",
    "# Calculate tournament wins and losses for each team\n",
    "tourney_wins = tourney_results.groupby('WTeamID').size().reset_index(name='TournamentWins')\n",
    "tourney_losses = tourney_results.groupby('LTeamID').size().reset_index(name='TournamentLosses')\n",
    "\n",
    "# Rename columns for consistency before merging\n",
    "tourney_wins.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "tourney_losses.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Merge win and loss data for each team\n",
    "tourney_stats = pd.merge(tourney_wins, tourney_losses, on='TeamID', how='outer')\n",
    "\n",
    "# Replace missing values with zero and ensure integer data type\n",
    "tourney_stats.fillna(0, inplace=True)\n",
    "tourney_stats = tourney_stats.astype({'TournamentWins': 'int', 'TournamentLosses': 'int'})\n",
    "\n",
    "# Calculate tournament win rate while handling cases where no games were played\n",
    "tourney_stats['TournamentWinRate'] = tourney_stats.apply(\n",
    "    lambda row: row['TournamentWins'] / (row['TournamentWins'] + row['TournamentLosses']) \n",
    "    if (row['TournamentWins'] + row['TournamentLosses']) > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Calculate average score difference in tournament games\n",
    "tourney_results['ScoreDiff'] = tourney_results['WScore'] - tourney_results['LScore']\n",
    "score_diff = tourney_results.groupby('WTeamID')['ScoreDiff'].mean().reset_index()\n",
    "score_diff.rename(columns={'WTeamID': 'TeamID', 'ScoreDiff': 'AvgTournamentScoreDiff'}, inplace=True)\n",
    "\n",
    "# Merge calculated features\n",
    "tourney_features = pd.merge(\n",
    "    tourney_stats[['TeamID', 'TournamentWinRate']], \n",
    "    score_diff, \n",
    "    on='TeamID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace missing values in score difference with zero\n",
    "tourney_features['AvgTournamentScoreDiff'] = tourney_features['AvgTournamentScoreDiff'].fillna(0)\n",
    "\n",
    "# Save the processed tournament features\n",
    "tourney_features.to_csv('/kaggle/working/tourney_features.csv', index=False)\n",
    "\n",
    "# Display a preview of the results\n",
    "print(\"Tournament features preview:\")\n",
    "print(tourney_features[['TeamID', 'TournamentWinRate', 'AvgTournamentScoreDiff']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51439abf",
   "metadata": {
    "papermill": {
     "duration": 0.010775,
     "end_time": "2025-03-03T08:40:09.181793",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.171018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating the percentage of successful shots for each team and the rate of extra time from the detailed results of the men's tournaments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cae60ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:09.205352Z",
     "iopub.status.busy": "2025-03-03T08:40:09.204838Z",
     "iopub.status.idle": "2025-03-03T08:40:09.241757Z",
     "shell.execute_reply": "2025-03-03T08:40:09.240218Z"
    },
    "papermill": {
     "duration": 0.051082,
     "end_time": "2025-03-03T08:40:09.243871",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.192789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed tournament features preview:\n",
      "   TeamID  AvgFieldGoalPercentage  AvgOTGames\n",
      "0    1101                0.305836    0.000000\n",
      "1    1102                0.474046    0.000000\n",
      "2    1103                0.370330    0.000000\n",
      "3    1104                0.458859    0.043478\n",
      "4    1105                0.389831    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load detailed tournament results data\n",
    "tourney_detailed = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyDetailedResults.csv')\n",
    "\n",
    "# Extract relevant columns for winning teams: TeamID, Field Goals Made (FGM), Field Goals Attempted (FGA), and Overtime count\n",
    "winners = tourney_detailed[['WTeamID', 'WFGM', 'WFGA', 'NumOT']].copy()\n",
    "winners.rename(columns={'WTeamID': 'TeamID', 'WFGM': 'FGM', 'WFGA': 'FGA'}, inplace=True)\n",
    "\n",
    "# Extract relevant columns for losing teams: TeamID, Field Goals Made (FGM), Field Goals Attempted (FGA), and Overtime count\n",
    "losers = tourney_detailed[['LTeamID', 'LFGM', 'LFGA', 'NumOT']].copy()\n",
    "losers.rename(columns={'LTeamID': 'TeamID', 'LFGM': 'FGM', 'LFGA': 'FGA'}, inplace=True)\n",
    "\n",
    "# Combine winners and losers into a single dataset for shot statistics\n",
    "teams_shots = pd.concat([winners, losers])\n",
    "\n",
    "# Calculate the field goal percentage for each team\n",
    "teams_shots['FG%'] = np.where(teams_shots['FGA'] > 0, teams_shots['FGM'] / teams_shots['FGA'], 0)\n",
    "\n",
    "# Compute the average field goal percentage for each team across all tournament games\n",
    "fg_percentage = teams_shots.groupby('TeamID')['FG%'].mean().reset_index()\n",
    "fg_percentage.rename(columns={'FG%': 'AvgFieldGoalPercentage'}, inplace=True)\n",
    "\n",
    "# Compute the average number of overtime games per team\n",
    "ot_games = teams_shots.groupby('TeamID')['NumOT'].mean().reset_index()\n",
    "ot_games.rename(columns={'NumOT': 'AvgOTGames'}, inplace=True)\n",
    "\n",
    "# Merge the computed features into a single dataset\n",
    "detailed_features = fg_percentage.merge(ot_games, on='TeamID', how='left')\n",
    "\n",
    "# Save the final dataset\n",
    "detailed_features.to_csv('/kaggle/working/detailed_features.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"Detailed tournament features preview:\")\n",
    "print(detailed_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d6532",
   "metadata": {
    "papermill": {
     "duration": 0.010712,
     "end_time": "2025-03-03T08:40:09.265933",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.255221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating Win Rate and Average Points Difference in Regular Season Under Pressure for Men:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54c3901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:09.289520Z",
     "iopub.status.busy": "2025-03-03T08:40:09.289107Z",
     "iopub.status.idle": "2025-03-03T08:40:09.550294Z",
     "shell.execute_reply": "2025-03-03T08:40:09.548900Z"
    },
    "papermill": {
     "duration": 0.275474,
     "end_time": "2025-03-03T08:40:09.552517",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.277043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Season Features Preview:\n",
      "   TeamID  SeasonWins  SeasonLosses  SeasonWinRate  AvgSeasonScoreDiff\n",
      "0    1101         148           167       0.469841           11.243243\n",
      "1    1102         395           710       0.357466           11.903797\n",
      "2    1103         689           484       0.587383           12.503628\n",
      "3    1104         795           464       0.631454           13.695597\n",
      "4    1105         244           456       0.348571           10.188525\n"
     ]
    }
   ],
   "source": [
    "# Load Regular Season Results Data\n",
    "season_results = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonCompactResults.csv')\n",
    "\n",
    "# Compute the number of wins for each team\n",
    "season_wins = season_results.groupby('WTeamID').size().reset_index(name='SeasonWins')\n",
    "season_wins.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Compute the number of losses for each team\n",
    "season_losses = season_results.groupby('LTeamID').size().reset_index(name='SeasonLosses')\n",
    "season_losses.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Merge wins and losses into a single dataset (ensuring all teams are included)\n",
    "season_stats = pd.merge(season_wins, season_losses, on='TeamID', how='outer').fillna(0)\n",
    "\n",
    "# Ensure numerical data types\n",
    "season_stats[['SeasonWins', 'SeasonLosses']] = season_stats[['SeasonWins', 'SeasonLosses']].astype(int)\n",
    "\n",
    "# Compute the win rate for each team\n",
    "season_stats['SeasonWinRate'] = season_stats['SeasonWins'] / (season_stats['SeasonWins'] + season_stats['SeasonLosses'])\n",
    "\n",
    "# Calculate the average points difference in the regular season\n",
    "season_results['ScoreDiff'] = season_results['WScore'] - season_results['LScore']\n",
    "avg_score_diff = season_results.groupby('WTeamID')['ScoreDiff'].mean().reset_index()\n",
    "avg_score_diff.rename(columns={'WTeamID': 'TeamID', 'ScoreDiff': 'AvgSeasonScoreDiff'}, inplace=True)\n",
    "\n",
    "# Merge the computed features into a single dataset\n",
    "season_features = season_stats.merge(avg_score_diff, on='TeamID', how='left')\n",
    "\n",
    "# Fill missing values for score difference with 0\n",
    "season_features['AvgSeasonScoreDiff'] = season_features['AvgSeasonScoreDiff'].fillna(0)\n",
    "\n",
    "# Save the final dataset\n",
    "season_features.to_csv('/kaggle/working/season_features.csv', index=False)\n",
    "\n",
    "# Display a preview of the dataset\n",
    "print(\"Regular Season Features Preview:\")\n",
    "print(season_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ebe95",
   "metadata": {
    "papermill": {
     "duration": 0.010479,
     "end_time": "2025-03-03T08:40:09.574360",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.563881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating successful shooting percentage and average points conceded for each team from the detailed results of the men's regular season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47ee7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:09.598312Z",
     "iopub.status.busy": "2025-03-03T08:40:09.597913Z",
     "iopub.status.idle": "2025-03-03T08:40:10.215544Z",
     "shell.execute_reply": "2025-03-03T08:40:10.214117Z"
    },
    "papermill": {
     "duration": 0.632473,
     "end_time": "2025-03-03T08:40:10.217811",
     "exception": false,
     "start_time": "2025-03-03T08:40:09.585338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  AvgFieldGoalPercentageSeason  AvgPointsAllowed  AvgPointsScored\n",
      "0    1101                      0.487839         71.285714        69.761905\n",
      "1    1102                      0.490937         65.689759        63.759036\n",
      "2    1103                      0.470686         67.280851        72.295035\n",
      "3    1104                      0.465272         68.543296        73.317039\n",
      "4    1105                      0.458149         71.444623        64.778491\n"
     ]
    }
   ],
   "source": [
    "# Load detailed results for the regular season\n",
    "season_detailed = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonDetailedResults.csv')\n",
    "\n",
    "# Extract relevant stats for the winning team (field goals made/attempted, points scored, and points allowed)\n",
    "winners = season_detailed[['WTeamID', 'WFGM', 'WFGA', 'LScore', 'WScore']].copy()\n",
    "winners.rename(columns={'WTeamID': 'TeamID', 'WFGM': 'FGM', 'WFGA': 'FGA', \n",
    "                          'LScore': 'PointsAllowed', 'WScore': 'PointsScored'}, inplace=True)\n",
    "\n",
    "# Extract relevant stats for the losing team (same stats as winners)\n",
    "losers = season_detailed[['LTeamID', 'LScore', 'WFGM', 'WFGA', 'WScore']].copy()\n",
    "losers.rename(columns={'LTeamID': 'TeamID', 'LScore': 'PointsScored', 'WFGM': 'FGM', \n",
    "                         'WFGA': 'FGA', 'WScore': 'PointsAllowed'}, inplace=True)\n",
    "\n",
    "# Combine winners and losers into a single dataset\n",
    "teams_stats = pd.concat([winners, losers], ignore_index=True)\n",
    "\n",
    "# Ensure FGA values are non-negative\n",
    "teams_stats['FGA'] = teams_stats['FGA'].clip(lower=0)\n",
    "\n",
    "# Calculate field goal percentage (avoiding division by zero)\n",
    "teams_stats['FG%'] = np.where(teams_stats['FGA'] > 0, teams_stats['FGM'] / teams_stats['FGA'], 0)\n",
    "\n",
    "# Compute the average field goal percentage for each team\n",
    "fg_percentage_season = teams_stats.groupby('TeamID')['FG%'].mean().reset_index().rename(\n",
    "    columns={'FG%': 'AvgFieldGoalPercentageSeason'}\n",
    ")\n",
    "\n",
    "# Compute the average points allowed (defensive strength) for each team\n",
    "defensive_strength = teams_stats.groupby('TeamID')['PointsAllowed'].mean().reset_index().rename(\n",
    "    columns={'PointsAllowed': 'AvgPointsAllowed'}\n",
    ")\n",
    "\n",
    "# Compute the average points scored (offensive strength) for each team\n",
    "offensive_strength= teams_stats.groupby('TeamID')['PointsScored'].mean().reset_index().rename(\n",
    "    columns={'PointsScored': 'AvgPointsScored'}\n",
    ")\n",
    "\n",
    "# Merge all extracted features into a single dataset\n",
    "season_detailed_features = fg_percentage_season.merge(defensive_strength, on='TeamID', how='left')\n",
    "season_detailed_features = season_detailed_features.merge(offensive_strength, on='TeamID', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "season_detailed_features = season_detailed_features.fillna(0)\n",
    "\n",
    "# Save the feature dataset\n",
    "season_detailed_features.to_csv('/kaggle/working/season_detailed_features.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(season_detailed_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40db3a",
   "metadata": {
    "papermill": {
     "duration": 0.010869,
     "end_time": "2025-03-03T08:40:10.239993",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.229124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating win rate and performance difference for each team in a men's secondary game under pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbe2727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:10.263399Z",
     "iopub.status.busy": "2025-03-03T08:40:10.263004Z",
     "iopub.status.idle": "2025-03-03T08:40:10.313503Z",
     "shell.execute_reply": "2025-03-03T08:40:10.312225Z"
    },
    "papermill": {
     "duration": 0.064784,
     "end_time": "2025-03-03T08:40:10.315721",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.250937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary Tournament Features Preview:\n",
      "   TeamID  SecondaryTourneyWinRate  SecondaryTourneyPressureWinRate\n",
      "0    1101                 0.500000                         0.500000\n",
      "1    1102                 0.625000                         0.666667\n",
      "2    1103                 0.250000                         0.428571\n",
      "3    1104                 0.538462                         0.375000\n",
      "4    1105                 0.500000                         0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the secondary tournament results\n",
    "secondary_tourney_results = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MSecondaryTourneyCompactResults.csv')\n",
    "\n",
    "# Calculate the number of wins and losses in the secondary tournament\n",
    "secondary_tourney_wins = secondary_tourney_results.groupby('WTeamID').size().reset_index(name='SecondaryTourneyWins')\n",
    "secondary_tourney_losses = secondary_tourney_results.groupby('LTeamID').size().reset_index(name='SecondaryTourneyLosses')\n",
    "\n",
    "# Merge win and loss data\n",
    "secondary_tourney_stats = pd.merge(\n",
    "    secondary_tourney_wins, secondary_tourney_losses, \n",
    "    left_on='WTeamID', right_on='LTeamID', how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Assign TeamID correctly\n",
    "secondary_tourney_stats['TeamID'] = secondary_tourney_stats['WTeamID'].fillna(secondary_tourney_stats['LTeamID']).astype(int)\n",
    "\n",
    "# Compute win rate in the secondary tournament, handling division by zero\n",
    "secondary_tourney_stats['SecondaryTourneyWinRate'] = np.where(\n",
    "    (secondary_tourney_stats['SecondaryTourneyWins'] + secondary_tourney_stats['SecondaryTourneyLosses']) > 0,\n",
    "    secondary_tourney_stats['SecondaryTourneyWins'] / (secondary_tourney_stats['SecondaryTourneyWins'] + secondary_tourney_stats['SecondaryTourneyLosses']),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Define games played under pressure:\n",
    "# Conditions: overtime (NumOT > 0) or close games (point difference <= 5)\n",
    "secondary_tourney_results['ScoreDiff'] = secondary_tourney_results['WScore'] - secondary_tourney_results['LScore']\n",
    "pressure_games = secondary_tourney_results[\n",
    "    (secondary_tourney_results['NumOT'] > 0) | (secondary_tourney_results['ScoreDiff'].abs() <= 5)\n",
    "]\n",
    "\n",
    "# Compute win and loss counts under pressure\n",
    "pressure_wins = pressure_games.groupby('WTeamID').size().reset_index(name='PressureWins')\n",
    "pressure_losses = pressure_games.groupby('LTeamID').size().reset_index(name='PressureLosses')\n",
    "\n",
    "# Merge pressure-based performance data\n",
    "pressure_stats = pd.merge(\n",
    "    pressure_wins, pressure_losses, \n",
    "    left_on='WTeamID', right_on='LTeamID', how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Assign TeamID correctly\n",
    "pressure_stats['TeamID'] = pressure_stats['WTeamID'].fillna(pressure_stats['LTeamID']).astype(int)\n",
    "\n",
    "# Compute win rate under pressure, handling division by zero\n",
    "pressure_stats['SecondaryTourneyPressureWinRate'] = np.where(\n",
    "    (pressure_stats['PressureWins'] + pressure_stats['PressureLosses']) > 0,\n",
    "    pressure_stats['PressureWins'] / (pressure_stats['PressureWins'] + pressure_stats['PressureLosses']),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Merge extracted features\n",
    "secondary_tourney_features = pd.merge(\n",
    "    secondary_tourney_stats[['TeamID', 'SecondaryTourneyWinRate']],\n",
    "    pressure_stats[['TeamID', 'SecondaryTourneyPressureWinRate']],\n",
    "    on='TeamID',\n",
    "    how='left'\n",
    ").fillna(0)\n",
    "\n",
    "# Save the feature file\n",
    "secondary_tourney_features.to_csv('/kaggle/working/secondary_tourney_features.csv', index=False)\n",
    "\n",
    "# Preview results\n",
    "print(\"Secondary Tournament Features Preview:\")\n",
    "print(secondary_tourney_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69e3c8",
   "metadata": {
    "papermill": {
     "duration": 0.01071,
     "end_time": "2025-03-03T08:40:10.337664",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.326954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating each team's experience in the first division using MTeams data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a9325c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:10.361426Z",
     "iopub.status.busy": "2025-03-03T08:40:10.361041Z",
     "iopub.status.idle": "2025-03-03T08:40:10.381168Z",
     "shell.execute_reply": "2025-03-03T08:40:10.379227Z"
    },
    "papermill": {
     "duration": 0.034677,
     "end_time": "2025-03-03T08:40:10.383344",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.348667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams Data Preview:\n",
      "   TeamID     TeamName  D1Experience\n",
      "0    1101  Abilene Chr            12\n",
      "1    1102    Air Force            41\n",
      "2    1103        Akron            41\n",
      "3    1104      Alabama            41\n",
      "4    1105  Alabama A&M            26\n"
     ]
    }
   ],
   "source": [
    "# Load men's team data\n",
    "teams = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MTeams.csv')\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = {'TeamID', 'FirstD1Season', 'LastD1Season'}\n",
    "if not required_columns.issubset(teams.columns):\n",
    "    missing_columns = required_columns - set(teams.columns)\n",
    "    raise KeyError(f\"The MTeams file is missing the following columns: {missing_columns}\")\n",
    "\n",
    "# Calculate each team's experience in the first division (D1)\n",
    "teams['D1Experience'] = teams['LastD1Season'] - teams['FirstD1Season'] + 1\n",
    "\n",
    "# Save extracted feature file\n",
    "teams.to_csv('/kaggle/working/teams.csv', index=False)\n",
    "\n",
    "# Preview final results (check if 'TeamName' exists before using it)\n",
    "preview_columns = ['TeamID', 'D1Experience']\n",
    "if 'TeamName' in teams.columns:\n",
    "    preview_columns.insert(1, 'TeamName')\n",
    "\n",
    "print(\"Teams Data Preview:\")\n",
    "print(teams[preview_columns].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500b774",
   "metadata": {
    "papermill": {
     "duration": 0.011772,
     "end_time": "2025-03-03T08:40:10.408493",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.396721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Merge all extracted feature files for men:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca52cdda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:10.432842Z",
     "iopub.status.busy": "2025-03-03T08:40:10.432412Z",
     "iopub.status.idle": "2025-03-03T08:40:10.486124Z",
     "shell.execute_reply": "2025-03-03T08:40:10.484205Z"
    },
    "papermill": {
     "duration": 0.06815,
     "end_time": "2025-03-03T08:40:10.488124",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.419974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Preview:\n",
      "   TeamID  TeamConferenceWinRate  TournamentWinRate  AvgTournamentScoreDiff  \\\n",
      "0    1101               0.700000           0.333333                1.000000   \n",
      "1    1102               0.200000           0.000000                0.000000   \n",
      "2    1103               0.678571           0.000000                0.000000   \n",
      "3    1104               0.522727           0.574468               10.555556   \n",
      "4    1105               0.428571           0.000000                0.000000   \n",
      "\n",
      "   AvgFieldGoalPercentage  AvgOTGames  SeasonWinRate  AvgSeasonScoreDiff  \\\n",
      "0                0.305836    0.000000       0.469841           11.243243   \n",
      "1                0.474046    0.000000       0.357466           11.903797   \n",
      "2                0.370330    0.000000       0.587383           12.503628   \n",
      "3                0.458859    0.043478       0.631454           13.695597   \n",
      "4                0.389831    0.000000       0.348571           10.188525   \n",
      "\n",
      "   AvgFieldGoalPercentageSeason  AvgPointsAllowed  AvgPointsScored  \\\n",
      "0                      0.487839         71.285714        69.761905   \n",
      "1                      0.490937         65.689759        63.759036   \n",
      "2                      0.470686         67.280851        72.295035   \n",
      "3                      0.465272         68.543296        73.317039   \n",
      "4                      0.458149         71.444623        64.778491   \n",
      "\n",
      "   SecondaryTourneyWinRate  SecondaryTourneyPressureWinRate  D1Experience  \n",
      "0                 0.500000                         0.500000            12  \n",
      "1                 0.625000                         0.666667            41  \n",
      "2                 0.250000                         0.428571            41  \n",
      "3                 0.538462                         0.375000            41  \n",
      "4                 0.500000                         0.000000            26  \n",
      "\n",
      "Data Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   TeamID                           363 non-null    int64  \n",
      " 1   TeamConferenceWinRate            363 non-null    float64\n",
      " 2   TournamentWinRate                363 non-null    float64\n",
      " 3   AvgTournamentScoreDiff           363 non-null    float64\n",
      " 4   AvgFieldGoalPercentage           363 non-null    float64\n",
      " 5   AvgOTGames                       363 non-null    float64\n",
      " 6   SeasonWinRate                    363 non-null    float64\n",
      " 7   AvgSeasonScoreDiff               363 non-null    float64\n",
      " 8   AvgFieldGoalPercentageSeason     363 non-null    float64\n",
      " 9   AvgPointsAllowed                 363 non-null    float64\n",
      " 10  AvgPointsScored                  363 non-null    float64\n",
      " 11  SecondaryTourneyWinRate          363 non-null    float64\n",
      " 12  SecondaryTourneyPressureWinRate  363 non-null    float64\n",
      " 13  D1Experience                     363 non-null    int64  \n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 39.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load all feature files\n",
    "conference_summary = pd.read_csv('conference_summary.csv', low_memory=False)\n",
    "tourney_features = pd.read_csv('tourney_features.csv', low_memory=False)\n",
    "detailed_features = pd.read_csv('detailed_features.csv', low_memory=False)\n",
    "season_features = pd.read_csv('season_features.csv', low_memory=False)\n",
    "season_detailed_features = pd.read_csv('season_detailed_features.csv', low_memory=False)\n",
    "secondary_tourney_features = pd.read_csv('secondary_tourney_features.csv', low_memory=False)\n",
    "teams = pd.read_csv('teams.csv', low_memory=False)\n",
    "\n",
    "# Merge all files based on TeamID\n",
    "merged_df = (\n",
    "    conference_summary[['TeamID', 'TeamConferenceWinRate']]\n",
    "    .merge(tourney_features[['TeamID', 'TournamentWinRate', 'AvgTournamentScoreDiff']], on='TeamID', how='left')\n",
    "    .merge(detailed_features[['TeamID', 'AvgFieldGoalPercentage', 'AvgOTGames']], on='TeamID', how='left')\n",
    "    .merge(season_features[['TeamID', 'SeasonWinRate', 'AvgSeasonScoreDiff']], on='TeamID', how='left')\n",
    "    .merge(season_detailed_features[['TeamID', 'AvgFieldGoalPercentageSeason', 'AvgPointsAllowed', 'AvgPointsScored']], on='TeamID', how='left')  # ✅ إضافة AvgPointsScored\n",
    "    .merge(secondary_tourney_features[['TeamID', 'SecondaryTourneyWinRate', 'SecondaryTourneyPressureWinRate']], on='TeamID', how='left')\n",
    "    .merge(teams[['TeamID', 'D1Experience']], on='TeamID', how='left')\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (important to avoid NaN issues)\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the merged file\n",
    "merged_df.to_csv('/kaggle/working/merged_team_features.csv', index=False)\n",
    "\n",
    "# Show preliminary results\n",
    "print(\"Merged Data Preview:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nData Overview:\")\n",
    "print(merged_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33cb62",
   "metadata": {
    "papermill": {
     "duration": 0.011491,
     "end_time": "2025-03-03T08:40:10.512089",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.500598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create all possible combinations of teams so that each pair consists of two different men's teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "630d48a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:40:10.537480Z",
     "iopub.status.busy": "2025-03-03T08:40:10.537082Z",
     "iopub.status.idle": "2025-03-03T08:41:14.051564Z",
     "shell.execute_reply": "2025-03-03T08:41:14.050401Z"
    },
    "papermill": {
     "duration": 63.540717,
     "end_time": "2025-03-03T08:41:14.064529",
     "exception": false,
     "start_time": "2025-03-03T08:40:10.523812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The file 'team_pairs_diff.csv' was created successfully!\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Load the dataset containing team features\n",
    "file_path = \"merged_team_features.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Generate all possible team matchups (unique pairs of teams)\n",
    "team_pairs = list(combinations(df['TeamID'], 2))\n",
    "\n",
    "# Define column names for the new DataFrame\n",
    "columns = ['TeamID1', 'TeamID2'] + [f'{col}_diff' for col in df.columns if col != 'TeamID'] + ['WinProbability']\n",
    "\n",
    "# Initialize a list to store the processed matchups\n",
    "data = []\n",
    "\n",
    "# Iterate through all possible team pairs\n",
    "for team1, team2 in team_pairs:\n",
    "    # Retrieve data for both teams\n",
    "    team1_data = df[df['TeamID'] == team1].squeeze()\n",
    "    team2_data = df[df['TeamID'] == team2].squeeze()\n",
    "    \n",
    "    # Skip if data for any team is missing\n",
    "    if team1_data.empty or team2_data.empty:\n",
    "        continue  \n",
    "    \n",
    "    # Store team IDs\n",
    "    row = {'TeamID1': team1, 'TeamID2': team2}\n",
    "    \n",
    "    # Compute feature differences between the two teams\n",
    "    feature_diffs = []\n",
    "    for col in df.columns:\n",
    "        if col != 'TeamID':\n",
    "            diff = team1_data[col] - team2_data[col]\n",
    "            if pd.isna(diff):  # Handle missing values\n",
    "                diff = 0\n",
    "            row[f'{col}_diff'] = diff\n",
    "            feature_diffs.append(diff)\n",
    "    \n",
    "    # Compute the estimated win probability using the logistic function\n",
    "    feature_sum = sum(feature_diffs)\n",
    "    \n",
    "    if np.isfinite(feature_sum):  # Ensure the value is valid before applying the function\n",
    "        row['WinProbability'] = round(1 / (1 + np.exp(-feature_sum)), 2)\n",
    "    else:\n",
    "        row['WinProbability'] = 0.5  # Assign a neutral probability in case of invalid values\n",
    "    \n",
    "    # Append the computed row to the data list\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list into a DataFrame\n",
    "pairs_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "pairs_df.to_csv(\"/kaggle/working/team_pairs_diff.csv\", index=False)\n",
    "\n",
    "# Print success message\n",
    "print(\" The file 'team_pairs_diff.csv' was created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233798a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:41:14.088646Z",
     "iopub.status.busy": "2025-03-03T08:41:14.088231Z",
     "iopub.status.idle": "2025-03-03T08:41:14.353830Z",
     "shell.execute_reply": "2025-03-03T08:41:14.352582Z"
    },
    "papermill": {
     "duration": 0.27987,
     "end_time": "2025-03-03T08:41:14.355830",
     "exception": false,
     "start_time": "2025-03-03T08:41:14.075960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID1</th>\n",
       "      <th>TeamID2</th>\n",
       "      <th>TeamConferenceWinRate_diff</th>\n",
       "      <th>TournamentWinRate_diff</th>\n",
       "      <th>AvgTournamentScoreDiff_diff</th>\n",
       "      <th>AvgFieldGoalPercentage_diff</th>\n",
       "      <th>AvgOTGames_diff</th>\n",
       "      <th>SeasonWinRate_diff</th>\n",
       "      <th>AvgSeasonScoreDiff_diff</th>\n",
       "      <th>AvgFieldGoalPercentageSeason_diff</th>\n",
       "      <th>AvgPointsAllowed_diff</th>\n",
       "      <th>AvgPointsScored_diff</th>\n",
       "      <th>SecondaryTourneyWinRate_diff</th>\n",
       "      <th>SecondaryTourneyPressureWinRate_diff</th>\n",
       "      <th>D1Experience_diff</th>\n",
       "      <th>WinProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.168210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112375</td>\n",
       "      <td>-0.660554</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>5.595955</td>\n",
       "      <td>6.002869</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.117542</td>\n",
       "      <td>-1.260385</td>\n",
       "      <td>0.017153</td>\n",
       "      <td>4.004863</td>\n",
       "      <td>-2.533131</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>0.177273</td>\n",
       "      <td>-0.241135</td>\n",
       "      <td>-9.555556</td>\n",
       "      <td>-0.153023</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>-0.161612</td>\n",
       "      <td>-2.452354</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>2.742418</td>\n",
       "      <td>-3.555134</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121270</td>\n",
       "      <td>1.054719</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>-0.158909</td>\n",
       "      <td>4.983414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101</td>\n",
       "      <td>1106</td>\n",
       "      <td>0.159459</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>1.322303</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>2.096607</td>\n",
       "      <td>4.600029</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65698</th>\n",
       "      <td>1474</td>\n",
       "      <td>1477</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201860</td>\n",
       "      <td>3.021905</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>2.927547</td>\n",
       "      <td>8.930389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65699</th>\n",
       "      <td>1474</td>\n",
       "      <td>1478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130907</td>\n",
       "      <td>-3.369674</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>2.294381</td>\n",
       "      <td>5.494891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65700</th>\n",
       "      <td>1475</td>\n",
       "      <td>1477</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023979</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>-0.020358</td>\n",
       "      <td>0.480954</td>\n",
       "      <td>3.515895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65701</th>\n",
       "      <td>1475</td>\n",
       "      <td>1478</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.046974</td>\n",
       "      <td>-4.191579</td>\n",
       "      <td>-0.020567</td>\n",
       "      <td>-0.152213</td>\n",
       "      <td>0.080397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65702</th>\n",
       "      <td>1477</td>\n",
       "      <td>1478</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.070953</td>\n",
       "      <td>-6.391579</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.633167</td>\n",
       "      <td>-3.435497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65703 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TeamID1  TeamID2  TeamConferenceWinRate_diff  TournamentWinRate_diff  \\\n",
       "0         1101     1102                    0.500000                0.333333   \n",
       "1         1101     1103                    0.021429                0.333333   \n",
       "2         1101     1104                    0.177273               -0.241135   \n",
       "3         1101     1105                    0.271429                0.333333   \n",
       "4         1101     1106                    0.159459                0.333333   \n",
       "...        ...      ...                         ...                     ...   \n",
       "65698     1474     1477                    0.166667                0.000000   \n",
       "65699     1474     1478                    0.000000                0.000000   \n",
       "65700     1475     1477                   -0.333333                0.000000   \n",
       "65701     1475     1478                   -0.500000                0.000000   \n",
       "65702     1477     1478                   -0.166667                0.000000   \n",
       "\n",
       "       AvgTournamentScoreDiff_diff  AvgFieldGoalPercentage_diff  \\\n",
       "0                         1.000000                    -0.168210   \n",
       "1                         1.000000                    -0.064494   \n",
       "2                        -9.555556                    -0.153023   \n",
       "3                         1.000000                    -0.083995   \n",
       "4                         1.000000                    -0.044547   \n",
       "...                            ...                          ...   \n",
       "65698                     0.000000                     0.000000   \n",
       "65699                     0.000000                     0.000000   \n",
       "65700                     0.000000                     0.000000   \n",
       "65701                     0.000000                     0.000000   \n",
       "65702                     0.000000                     0.000000   \n",
       "\n",
       "       AvgOTGames_diff  SeasonWinRate_diff  AvgSeasonScoreDiff_diff  \\\n",
       "0             0.000000            0.112375                -0.660554   \n",
       "1             0.000000           -0.117542                -1.260385   \n",
       "2            -0.043478           -0.161612                -2.452354   \n",
       "3             0.000000            0.121270                 1.054719   \n",
       "4             0.000000            0.047839                 1.322303   \n",
       "...                ...                 ...                      ...   \n",
       "65698         0.000000            0.201860                 3.021905   \n",
       "65699         0.000000            0.130907                -3.369674   \n",
       "65700         0.000000            0.023979                 2.200000   \n",
       "65701         0.000000           -0.046974                -4.191579   \n",
       "65702         0.000000           -0.070953                -6.391579   \n",
       "\n",
       "       AvgFieldGoalPercentageSeason_diff  AvgPointsAllowed_diff  \\\n",
       "0                              -0.003098               5.595955   \n",
       "1                               0.017153               4.004863   \n",
       "2                               0.022567               2.742418   \n",
       "3                               0.029690              -0.158909   \n",
       "4                               0.028813               2.096607   \n",
       "...                                  ...                    ...   \n",
       "65698                           0.001367               2.927547   \n",
       "65699                           0.001159               2.294381   \n",
       "65700                          -0.020358               0.480954   \n",
       "65701                          -0.020567              -0.152213   \n",
       "65702                          -0.000209              -0.633167   \n",
       "\n",
       "       AvgPointsScored_diff  SecondaryTourneyWinRate_diff  \\\n",
       "0                  6.002869                     -0.125000   \n",
       "1                 -2.533131                      0.250000   \n",
       "2                 -3.555134                     -0.038462   \n",
       "3                  4.983414                      0.000000   \n",
       "4                  4.600029                      0.500000   \n",
       "...                     ...                           ...   \n",
       "65698              8.930389                      0.000000   \n",
       "65699              5.494891                      0.000000   \n",
       "65700              3.515895                      0.000000   \n",
       "65701              0.080397                      0.000000   \n",
       "65702             -3.435497                      0.000000   \n",
       "\n",
       "       SecondaryTourneyPressureWinRate_diff  D1Experience_diff  WinProbability  \n",
       "0                                 -0.166667              -29.0            0.00  \n",
       "1                                  0.071429              -29.0            0.00  \n",
       "2                                  0.125000              -29.0            0.00  \n",
       "3                                  0.500000              -14.0            0.00  \n",
       "4                                  0.500000              -29.0            0.00  \n",
       "...                                     ...                ...             ...  \n",
       "65698                              0.000000                0.0            1.00  \n",
       "65699                              0.000000                1.0            1.00  \n",
       "65700                              0.000000                0.0            1.00  \n",
       "65701                              0.000000                1.0            0.02  \n",
       "65702                              0.000000                1.0            0.00  \n",
       "\n",
       "[65703 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_pairs_diff = pd.read_csv(\"/kaggle/working/team_pairs_diff.csv\")\n",
    "team_pairs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12da136",
   "metadata": {
    "papermill": {
     "duration": 0.011459,
     "end_time": "2025-03-03T08:41:14.379663",
     "exception": false,
     "start_time": "2025-03-03T08:41:14.368204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model for predicting the probability of the team with the smallest ID for men winning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d140e",
   "metadata": {
    "papermill": {
     "duration": 0.011805,
     "end_time": "2025-03-03T08:41:14.403223",
     "exception": false,
     "start_time": "2025-03-03T08:41:14.391418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0e45a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:41:14.428455Z",
     "iopub.status.busy": "2025-03-03T08:41:14.428020Z",
     "iopub.status.idle": "2025-03-03T08:46:21.271234Z",
     "shell.execute_reply": "2025-03-03T08:46:21.269996Z"
    },
    "papermill": {
     "duration": 306.858941,
     "end_time": "2025-03-03T08:46:21.273881",
     "exception": false,
     "start_time": "2025-03-03T08:41:14.414940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-03 08:41:17,467] A new study created in memory with name: no-name-0b4e7cd8-fa95-45ac-81aa-0ba9072ff8c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (52562, 13), Testing set size: (13141, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:19,821] Trial 0 finished with value: 0.0061707521417067685 and parameters: {'n_estimators': 287, 'learning_rate': 0.19063571821788408, 'max_depth': 7, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'reg_alpha': 1.5599452033620265, 'reg_lambda': 1.5227525095137953}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:23,302] Trial 1 finished with value: 0.006595696811029697 and parameters: {'n_estimators': 533, 'learning_rate': 0.12421185223120967, 'max_depth': 7, 'subsample': 0.608233797718321, 'colsample_bytree': 0.9879639408647978, 'reg_alpha': 8.324426408004218, 'reg_lambda': 2.9110519961044856}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:24,201] Trial 2 finished with value: 0.016258768165486437 and parameters: {'n_estimators': 191, 'learning_rate': 0.044846856872152424, 'max_depth': 4, 'subsample': 0.8099025726528951, 'colsample_bytree': 0.7727780074568463, 'reg_alpha': 2.9122914019804194, 'reg_lambda': 6.506676052501415}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:25,156] Trial 3 finished with value: 0.01071363767855735 and parameters: {'n_estimators': 169, 'learning_rate': 0.06550748322169145, 'max_depth': 5, 'subsample': 0.7824279936868144, 'colsample_bytree': 0.9140703845572055, 'reg_alpha': 1.9967378215835974, 'reg_lambda': 5.628109945722504}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:29,165] Trial 4 finished with value: 0.01315357624074527 and parameters: {'n_estimators': 396, 'learning_rate': 0.01882557841679957, 'max_depth': 6, 'subsample': 0.6682096494749166, 'colsample_bytree': 0.6260206371941118, 'reg_alpha': 9.488855372533333, 'reg_lambda': 9.690688297671034}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:31,117] Trial 5 finished with value: 0.01667280755952166 and parameters: {'n_estimators': 505, 'learning_rate': 0.06787661614294042, 'max_depth': 3, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7760609974958406, 'reg_alpha': 1.2203823484477883, 'reg_lambda': 5.456592191001432}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:31,729] Trial 6 finished with value: 0.013812835840836542 and parameters: {'n_estimators': 117, 'learning_rate': 0.1827708763949686, 'max_depth': 4, 'subsample': 0.8650089137415928, 'colsample_bytree': 0.7246844304357644, 'reg_alpha': 5.200680211778108, 'reg_lambda': 5.920392514089517}. Best is trial 0 with value: 0.0061707521417067685.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:33,130] Trial 7 finished with value: 0.00606968591456778 and parameters: {'n_estimators': 192, 'learning_rate': 0.19422107927526613, 'max_depth': 7, 'subsample': 0.9757995766256756, 'colsample_bytree': 0.9579309401710595, 'reg_alpha': 5.978999788110851, 'reg_lambda': 9.296868115208051}. Best is trial 7 with value: 0.00606968591456778.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:33,763] Trial 8 finished with value: 0.025014996146655727 and parameters: {'n_estimators': 144, 'learning_rate': 0.04723674385963759, 'max_depth': 3, 'subsample': 0.7301321323053057, 'colsample_bytree': 0.7554709158757928, 'reg_alpha': 2.713490317738959, 'reg_lambda': 8.458637582367365}. Best is trial 7 with value: 0.00606968591456778.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:35,614] Trial 9 finished with value: 0.007193092755439967 and parameters: {'n_estimators': 278, 'learning_rate': 0.06337755684060234, 'max_depth': 6, 'subsample': 0.6563696899899051, 'colsample_bytree': 0.9208787923016158, 'reg_alpha': 0.7455064367977082, 'reg_lambda': 9.881982429404655}. Best is trial 7 with value: 0.00606968591456778.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:38,196] Trial 10 finished with value: 0.005450403046211293 and parameters: {'n_estimators': 357, 'learning_rate': 0.1429762518851035, 'max_depth': 8, 'subsample': 0.9820559747905796, 'colsample_bytree': 0.8607466203112714, 'reg_alpha': 5.7520806681527255, 'reg_lambda': 7.573302056863087}. Best is trial 10 with value: 0.005450403046211293.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:40,393] Trial 11 finished with value: 0.0055824365739227605 and parameters: {'n_estimators': 412, 'learning_rate': 0.14614949759630771, 'max_depth': 8, 'subsample': 0.9981518123194613, 'colsample_bytree': 0.8716684361166434, 'reg_alpha': 5.745188822465942, 'reg_lambda': 7.524737412555459}. Best is trial 10 with value: 0.005450403046211293.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:42,046] Trial 12 finished with value: 0.006149662398814244 and parameters: {'n_estimators': 426, 'learning_rate': 0.1420845183098841, 'max_depth': 8, 'subsample': 0.9996024414136008, 'colsample_bytree': 0.8700857191344268, 'reg_alpha': 7.120145094472267, 'reg_lambda': 7.586424590967306}. Best is trial 10 with value: 0.005450403046211293.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:46,593] Trial 13 finished with value: 0.005094062778561246 and parameters: {'n_estimators': 597, 'learning_rate': 0.15206263106746948, 'max_depth': 8, 'subsample': 0.9443817145060609, 'colsample_bytree': 0.8287431543953531, 'reg_alpha': 3.9810911599065646, 'reg_lambda': 7.407800219920704}. Best is trial 13 with value: 0.005094062778561246.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:51,421] Trial 14 finished with value: 0.0050194038713832125 and parameters: {'n_estimators': 592, 'learning_rate': 0.10699935039661103, 'max_depth': 8, 'subsample': 0.9327492569671689, 'colsample_bytree': 0.8363231194086244, 'reg_alpha': 3.839000378855457, 'reg_lambda': 4.272077514182644}. Best is trial 14 with value: 0.0050194038713832125.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:41:56,304] Trial 15 finished with value: 0.004984513082463913 and parameters: {'n_estimators': 600, 'learning_rate': 0.10153262764691576, 'max_depth': 8, 'subsample': 0.9185231862138854, 'colsample_bytree': 0.8124420989639126, 'reg_alpha': 3.7427725822130493, 'reg_lambda': 4.201129093711064}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:02,311] Trial 16 finished with value: 0.005732024189559678 and parameters: {'n_estimators': 592, 'learning_rate': 0.10576008921064162, 'max_depth': 7, 'subsample': 0.916679827402116, 'colsample_bytree': 0.7066103592807617, 'reg_alpha': 4.008033895898112, 'reg_lambda': 4.040682623483784}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:05,464] Trial 17 finished with value: 0.006175810162514391 and parameters: {'n_estimators': 491, 'learning_rate': 0.09401089624364609, 'max_depth': 6, 'subsample': 0.9186007623689508, 'colsample_bytree': 0.8255130095102055, 'reg_alpha': 0.04740119653089092, 'reg_lambda': 3.861364277829173}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:08,356] Trial 18 finished with value: 0.007937361747492048 and parameters: {'n_estimators': 547, 'learning_rate': 0.09506381531477198, 'max_depth': 5, 'subsample': 0.9003736657086099, 'colsample_bytree': 0.8126345965706099, 'reg_alpha': 3.9910309246563687, 'reg_lambda': 4.225512563114876}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:12,346] Trial 19 finished with value: 0.005392554532605265 and parameters: {'n_estimators': 467, 'learning_rate': 0.11796347945868889, 'max_depth': 8, 'subsample': 0.7815758694620589, 'colsample_bytree': 0.710043527579618, 'reg_alpha': 3.1315082652390442, 'reg_lambda': 2.476499823795066}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:15,620] Trial 20 finished with value: 0.006029713971616438 and parameters: {'n_estimators': 558, 'learning_rate': 0.1662026994241383, 'max_depth': 7, 'subsample': 0.9493844363311728, 'colsample_bytree': 0.9102782293319922, 'reg_alpha': 7.262081983769571, 'reg_lambda': 4.751244093753448}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:19,974] Trial 21 finished with value: 0.0050404416741830545 and parameters: {'n_estimators': 591, 'learning_rate': 0.16556379923560452, 'max_depth': 8, 'subsample': 0.9439665547839595, 'colsample_bytree': 0.8365265689468061, 'reg_alpha': 4.268692784415128, 'reg_lambda': 3.0941521780217003}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:24,773] Trial 22 finished with value: 0.005221752247063469 and parameters: {'n_estimators': 596, 'learning_rate': 0.08633517759971084, 'max_depth': 8, 'subsample': 0.948503973547373, 'colsample_bytree': 0.8419704918756064, 'reg_alpha': 4.55377953641233, 'reg_lambda': 2.985406077596511}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:28,240] Trial 23 finished with value: 0.0053986352056417395 and parameters: {'n_estimators': 461, 'learning_rate': 0.12476549739606888, 'max_depth': 7, 'subsample': 0.8727315362117225, 'colsample_bytree': 0.8086226007064172, 'reg_alpha': 3.3319605199618314, 'reg_lambda': 1.1045886546479764}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:33,855] Trial 24 finished with value: 0.005286661737252693 and parameters: {'n_estimators': 535, 'learning_rate': 0.17003074375365587, 'max_depth': 8, 'subsample': 0.8333107710659, 'colsample_bytree': 0.8895330258469676, 'reg_alpha': 4.804229580670224, 'reg_lambda': 3.398311134151284}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:37,599] Trial 25 finished with value: 0.005804800497839326 and parameters: {'n_estimators': 552, 'learning_rate': 0.10839986595680497, 'max_depth': 8, 'subsample': 0.9043035607347976, 'colsample_bytree': 0.7882523689672937, 'reg_alpha': 6.760485909167491, 'reg_lambda': 2.0015724830338644}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:41,279] Trial 26 finished with value: 0.005670706854720491 and parameters: {'n_estimators': 502, 'learning_rate': 0.07840494888408163, 'max_depth': 7, 'subsample': 0.946470229878525, 'colsample_bytree': 0.7442578096512015, 'reg_alpha': 2.1424498896657997, 'reg_lambda': 5.0537305166868896}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:45,066] Trial 27 finished with value: 0.006058896844346967 and parameters: {'n_estimators': 573, 'learning_rate': 0.13064397531084476, 'max_depth': 6, 'subsample': 0.7365408631898037, 'colsample_bytree': 0.857125677947732, 'reg_alpha': 3.7459717336274756, 'reg_lambda': 4.705694038380803}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:47,867] Trial 28 finished with value: 0.011145147020137606 and parameters: {'n_estimators': 291, 'learning_rate': 0.01197363375456277, 'max_depth': 8, 'subsample': 0.8892444914998263, 'colsample_bytree': 0.8041742095389535, 'reg_alpha': 4.939604787804137, 'reg_lambda': 3.706883531453351}. Best is trial 15 with value: 0.004984513082463913.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:52,161] Trial 29 finished with value: 0.0047918056979285 and parameters: {'n_estimators': 520, 'learning_rate': 0.1735191763696266, 'max_depth': 7, 'subsample': 0.8402705171170026, 'colsample_bytree': 0.9475836556815316, 'reg_alpha': 2.1862829473999223, 'reg_lambda': 2.1942582476341532}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:55,854] Trial 30 finished with value: 0.004923126014435427 and parameters: {'n_estimators': 455, 'learning_rate': 0.17723684073292187, 'max_depth': 7, 'subsample': 0.8364869626968462, 'colsample_bytree': 0.9440163417454057, 'reg_alpha': 2.4037093096560227, 'reg_lambda': 1.8119585448406874}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:42:59,527] Trial 31 finished with value: 0.004882261224159756 and parameters: {'n_estimators': 454, 'learning_rate': 0.18271794114924106, 'max_depth': 7, 'subsample': 0.8432011621422343, 'colsample_bytree': 0.94723947721226, 'reg_alpha': 2.2318156370335016, 'reg_lambda': 1.7520287779229573}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:04,947] Trial 32 finished with value: 0.00491973501813055 and parameters: {'n_estimators': 442, 'learning_rate': 0.1795658754301903, 'max_depth': 7, 'subsample': 0.8466095647647858, 'colsample_bytree': 0.9838248308333566, 'reg_alpha': 2.332993112529886, 'reg_lambda': 1.878604075992509}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:08,596] Trial 33 finished with value: 0.004829729808108241 and parameters: {'n_estimators': 455, 'learning_rate': 0.18167920998564985, 'max_depth': 7, 'subsample': 0.8421375092402017, 'colsample_bytree': 0.9803888559654039, 'reg_alpha': 2.291547133774583, 'reg_lambda': 1.7749214652601193}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:11,156] Trial 34 finished with value: 0.005754875208011887 and parameters: {'n_estimators': 380, 'learning_rate': 0.19761089206982002, 'max_depth': 6, 'subsample': 0.7875360610709402, 'colsample_bytree': 0.9967389644907205, 'reg_alpha': 1.8764823680388076, 'reg_lambda': 2.388615327152898}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:14,889] Trial 35 finished with value: 0.004851737486951946 and parameters: {'n_estimators': 439, 'learning_rate': 0.18534898473957867, 'max_depth': 7, 'subsample': 0.8192739870230014, 'colsample_bytree': 0.9685188800325168, 'reg_alpha': 1.2856170618964389, 'reg_lambda': 1.493148037715855}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:17,536] Trial 36 finished with value: 0.006651756151437089 and parameters: {'n_estimators': 486, 'learning_rate': 0.15756528951679946, 'max_depth': 5, 'subsample': 0.80540630933865, 'colsample_bytree': 0.9542458135657029, 'reg_alpha': 1.2263225485678981, 'reg_lambda': 1.090014275061487}. Best is trial 29 with value: 0.0047918056979285.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:20,543] Trial 37 finished with value: 0.0046226134363694426 and parameters: {'n_estimators': 339, 'learning_rate': 0.18587380258887093, 'max_depth': 7, 'subsample': 0.7676688078875674, 'colsample_bytree': 0.9737862648332286, 'reg_alpha': 0.4491461553613423, 'reg_lambda': 2.4583694159557794}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:22,784] Trial 38 finished with value: 0.005776157619528984 and parameters: {'n_estimators': 300, 'learning_rate': 0.19101495341608468, 'max_depth': 6, 'subsample': 0.7603462978067852, 'colsample_bytree': 0.9773312514616794, 'reg_alpha': 0.19851801180551076, 'reg_lambda': 2.61256606512406}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:25,847] Trial 39 finished with value: 0.00471464135873668 and parameters: {'n_estimators': 343, 'learning_rate': 0.1997318938333719, 'max_depth': 7, 'subsample': 0.7154350604629772, 'colsample_bytree': 0.924764599658256, 'reg_alpha': 0.6987024563974489, 'reg_lambda': 1.1398958659364697}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:27,337] Trial 40 finished with value: 0.00945008459844214 and parameters: {'n_estimators': 317, 'learning_rate': 0.17096212259882215, 'max_depth': 4, 'subsample': 0.6912296176455228, 'colsample_bytree': 0.9251121320433306, 'reg_alpha': 0.6962243577643068, 'reg_lambda': 1.3966308195656816}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:30,233] Trial 41 finished with value: 0.005016406189679666 and parameters: {'n_estimators': 339, 'learning_rate': 0.18836963565199744, 'max_depth': 7, 'subsample': 0.7579467959626274, 'colsample_bytree': 0.9728984059205477, 'reg_alpha': 1.4385753862040531, 'reg_lambda': 2.2913451853726183}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:32,145] Trial 42 finished with value: 0.005747825753251595 and parameters: {'n_estimators': 259, 'learning_rate': 0.19884812753110476, 'max_depth': 6, 'subsample': 0.8152681495321137, 'colsample_bytree': 0.9302675098346876, 'reg_alpha': 0.6169099674848728, 'reg_lambda': 1.474804075628274}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:37,018] Trial 43 finished with value: 0.004758245976156681 and parameters: {'n_estimators': 383, 'learning_rate': 0.15776900674647124, 'max_depth': 7, 'subsample': 0.7059908139986178, 'colsample_bytree': 0.9604153986958932, 'reg_alpha': 0.9213157484520613, 'reg_lambda': 2.121357729895357}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:40,065] Trial 44 finished with value: 0.005111931677165672 and parameters: {'n_estimators': 375, 'learning_rate': 0.1579941470021003, 'max_depth': 7, 'subsample': 0.7007178998338495, 'colsample_bytree': 0.8932025651365683, 'reg_alpha': 1.7376108548701898, 'reg_lambda': 2.77924732250903}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:41,938] Trial 45 finished with value: 0.005892342681047909 and parameters: {'n_estimators': 257, 'learning_rate': 0.176987909770725, 'max_depth': 6, 'subsample': 0.6386342885448144, 'colsample_bytree': 0.9961878466566992, 'reg_alpha': 0.5358301252642244, 'reg_lambda': 3.354125423913352}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:45,255] Trial 46 finished with value: 0.004950996346861105 and parameters: {'n_estimators': 404, 'learning_rate': 0.19923692636686546, 'max_depth': 7, 'subsample': 0.7195331111227534, 'colsample_bytree': 0.9082257880864254, 'reg_alpha': 1.0303377580785695, 'reg_lambda': 2.140564890308397}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:47,940] Trial 47 finished with value: 0.0053430960145415445 and parameters: {'n_estimators': 337, 'learning_rate': 0.15933063803874506, 'max_depth': 7, 'subsample': 0.619775614767331, 'colsample_bytree': 0.9374545548629307, 'reg_alpha': 2.8273726405415376, 'reg_lambda': 1.1041520063981862}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:49,451] Trial 48 finished with value: 0.007957339923176371 and parameters: {'n_estimators': 223, 'learning_rate': 0.1899112552487692, 'max_depth': 6, 'subsample': 0.6784378554048333, 'colsample_bytree': 0.9638082831192897, 'reg_alpha': 9.694286635234583, 'reg_lambda': 2.7823867596334493}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:51,897] Trial 49 finished with value: 0.006770767737469121 and parameters: {'n_estimators': 363, 'learning_rate': 0.14611484586947499, 'max_depth': 7, 'subsample': 0.7163012243580714, 'colsample_bytree': 0.9573368808880971, 'reg_alpha': 8.932078456752281, 'reg_lambda': 2.1902288635352747}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:54,343] Trial 50 finished with value: 0.0066830850999531075 and parameters: {'n_estimators': 417, 'learning_rate': 0.13311457292821394, 'max_depth': 6, 'subsample': 0.7673929624023889, 'colsample_bytree': 0.6301410525479902, 'reg_alpha': 0.3703615997344467, 'reg_lambda': 6.089649819028433}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:43:58,715] Trial 51 finished with value: 0.004674348584491103 and parameters: {'n_estimators': 516, 'learning_rate': 0.18509619097181135, 'max_depth': 7, 'subsample': 0.8229308191159812, 'colsample_bytree': 0.9701372786377568, 'reg_alpha': 1.0654645933996991, 'reg_lambda': 1.5636258396930975}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:03,075] Trial 52 finished with value: 0.00464788270083678 and parameters: {'n_estimators': 508, 'learning_rate': 0.17370042177117725, 'max_depth': 7, 'subsample': 0.8611462394939623, 'colsample_bytree': 0.9988402459412085, 'reg_alpha': 0.9303731554400958, 'reg_lambda': 1.6360198619070803}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:09,089] Trial 53 finished with value: 0.0046429096948827405 and parameters: {'n_estimators': 521, 'learning_rate': 0.1753394964119673, 'max_depth': 7, 'subsample': 0.7408112390873881, 'colsample_bytree': 0.9918406771094096, 'reg_alpha': 0.80094245399829, 'reg_lambda': 1.2307840195141455}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:13,699] Trial 54 finished with value: 0.004630538260726065 and parameters: {'n_estimators': 522, 'learning_rate': 0.16371217775879632, 'max_depth': 7, 'subsample': 0.7413641650224574, 'colsample_bytree': 0.9990030280053492, 'reg_alpha': 0.9787890533355217, 'reg_lambda': 1.337120709502186}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:17,947] Trial 55 finished with value: 0.004676828030697985 and parameters: {'n_estimators': 513, 'learning_rate': 0.16618778711646198, 'max_depth': 7, 'subsample': 0.7417707225646601, 'colsample_bytree': 0.9947989189695086, 'reg_alpha': 1.5706109053230288, 'reg_lambda': 1.328547262112266}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:20,812] Trial 56 finished with value: 0.006569222229322472 and parameters: {'n_estimators': 514, 'learning_rate': 0.16468616611224804, 'max_depth': 5, 'subsample': 0.7370949991818644, 'colsample_bytree': 0.9950127297562451, 'reg_alpha': 1.606050360254398, 'reg_lambda': 1.4391370013755127}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:22,829] Trial 57 finished with value: 0.013003743392171856 and parameters: {'n_estimators': 482, 'learning_rate': 0.15101920457549367, 'max_depth': 3, 'subsample': 0.7471348655123125, 'colsample_bytree': 0.9992778164488857, 'reg_alpha': 0.06839340231480218, 'reg_lambda': 1.5959076355452628}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:26,372] Trial 58 finished with value: 0.006734598404875565 and parameters: {'n_estimators': 528, 'learning_rate': 0.036243408172453986, 'max_depth': 6, 'subsample': 0.7879959831441816, 'colsample_bytree': 0.9823563483520916, 'reg_alpha': 1.0500155896170043, 'reg_lambda': 1.0361156212681029}. Best is trial 37 with value: 0.0046226134363694426.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:32,104] Trial 59 finished with value: 0.004216960819638249 and parameters: {'n_estimators': 570, 'learning_rate': 0.13543311513190706, 'max_depth': 8, 'subsample': 0.7974251183637835, 'colsample_bytree': 0.971714468348793, 'reg_alpha': 1.5771401728587064, 'reg_lambda': 3.297374964570759}. Best is trial 59 with value: 0.004216960819638249.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:39,899] Trial 60 finished with value: 0.004127075562226189 and parameters: {'n_estimators': 570, 'learning_rate': 0.14037719511012875, 'max_depth': 8, 'subsample': 0.8587372446376077, 'colsample_bytree': 0.8981891728483166, 'reg_alpha': 0.4532015398928746, 'reg_lambda': 3.0779784992699177}. Best is trial 60 with value: 0.004127075562226189.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:46,520] Trial 61 finished with value: 0.004035453822304517 and parameters: {'n_estimators': 563, 'learning_rate': 0.13178241818551803, 'max_depth': 8, 'subsample': 0.7749824646341003, 'colsample_bytree': 0.9729415941858711, 'reg_alpha': 0.3136068892181022, 'reg_lambda': 3.165743804154165}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:52,900] Trial 62 finished with value: 0.004273960519757291 and parameters: {'n_estimators': 565, 'learning_rate': 0.1378486179833518, 'max_depth': 8, 'subsample': 0.7999491685487453, 'colsample_bytree': 0.8986772916331703, 'reg_alpha': 0.3465346662958507, 'reg_lambda': 3.510098519810582}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:44:59,398] Trial 63 finished with value: 0.004150568217766069 and parameters: {'n_estimators': 578, 'learning_rate': 0.13793798669893548, 'max_depth': 8, 'subsample': 0.7720832764947887, 'colsample_bytree': 0.8980275146686917, 'reg_alpha': 0.22154296306986357, 'reg_lambda': 3.2981555032054093}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:05,861] Trial 64 finished with value: 0.004211516402033305 and parameters: {'n_estimators': 567, 'learning_rate': 0.11573928178472112, 'max_depth': 8, 'subsample': 0.7756722832228206, 'colsample_bytree': 0.8910490832030655, 'reg_alpha': 0.35709653813110037, 'reg_lambda': 3.3542466510511226}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:13,478] Trial 65 finished with value: 0.004373266434703107 and parameters: {'n_estimators': 573, 'learning_rate': 0.13737687806205226, 'max_depth': 8, 'subsample': 0.7943286767854936, 'colsample_bytree': 0.8846099869693468, 'reg_alpha': 0.031059296938383163, 'reg_lambda': 3.5679628230653755}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:19,813] Trial 66 finished with value: 0.004236688355908645 and parameters: {'n_estimators': 571, 'learning_rate': 0.1380446270164111, 'max_depth': 8, 'subsample': 0.7960553684693796, 'colsample_bytree': 0.8802783823488834, 'reg_alpha': 0.1925299841931797, 'reg_lambda': 3.63104725618202}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:26,401] Trial 67 finished with value: 0.00408913972722403 and parameters: {'n_estimators': 571, 'learning_rate': 0.11661677143568014, 'max_depth': 8, 'subsample': 0.7801199648524982, 'colsample_bytree': 0.9005854452633694, 'reg_alpha': 0.21649618905798762, 'reg_lambda': 3.27982660572674}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:32,620] Trial 68 finished with value: 0.0041335657044069855 and parameters: {'n_estimators': 544, 'learning_rate': 0.11637516646255874, 'max_depth': 8, 'subsample': 0.7741743240550194, 'colsample_bytree': 0.8778750915269327, 'reg_alpha': 0.34365739897099257, 'reg_lambda': 3.1507047998795263}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:38,640] Trial 69 finished with value: 0.004181837115216627 and parameters: {'n_estimators': 553, 'learning_rate': 0.11418336247501656, 'max_depth': 8, 'subsample': 0.7793040821238963, 'colsample_bytree': 0.8504273460826995, 'reg_alpha': 0.4681478267379584, 'reg_lambda': 3.068711562473838}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:46,612] Trial 70 finished with value: 0.004226142722045652 and parameters: {'n_estimators': 549, 'learning_rate': 0.11797915426243294, 'max_depth': 8, 'subsample': 0.7754559022933595, 'colsample_bytree': 0.86494046060002, 'reg_alpha': 0.013597465150428534, 'reg_lambda': 4.270138402824466}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:52,955] Trial 71 finished with value: 0.00413843278449043 and parameters: {'n_estimators': 581, 'learning_rate': 0.11666182911387189, 'max_depth': 8, 'subsample': 0.7779840802645605, 'colsample_bytree': 0.9120731967686111, 'reg_alpha': 0.5387979977610231, 'reg_lambda': 3.110727986395768}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:45:58,706] Trial 72 finished with value: 0.004192986430191785 and parameters: {'n_estimators': 539, 'learning_rate': 0.11348557235306714, 'max_depth': 8, 'subsample': 0.7825488054785816, 'colsample_bytree': 0.8525336425361008, 'reg_alpha': 0.6731853023776114, 'reg_lambda': 3.0850995614288466}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:05,207] Trial 73 finished with value: 0.004059345622193717 and parameters: {'n_estimators': 586, 'learning_rate': 0.09933300938460198, 'max_depth': 8, 'subsample': 0.7542888878842527, 'colsample_bytree': 0.8568995726539445, 'reg_alpha': 0.5407942656723589, 'reg_lambda': 3.9314024907101093}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:11,193] Trial 74 finished with value: 0.004356018442270175 and parameters: {'n_estimators': 584, 'learning_rate': 0.12294782574035268, 'max_depth': 8, 'subsample': 0.7522146239357695, 'colsample_bytree': 0.8750603332256935, 'reg_alpha': 1.3124384620293579, 'reg_lambda': 4.588570567512307}. Best is trial 61 with value: 0.004035453822304517.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 563, 'learning_rate': 0.13178241818551803, 'max_depth': 8, 'subsample': 0.7749824646341003, 'colsample_bytree': 0.9729415941858711, 'reg_alpha': 0.3136068892181022, 'reg_lambda': 3.165743804154165}\n",
      "The file 'submission_m.csv' was created successfully!\n",
      "Mean Squared Error on Training Set: 0.0004\n",
      "Mean Squared Error on Test Set: 0.0041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# Define feature columns (all '_diff' columns) and target variable ('WinProbability')\n",
    "feature_columns = [col for col in pairs_df.columns if col.endswith('_diff')]\n",
    "X = pairs_df[feature_columns]\n",
    "y = pairs_df['WinProbability']\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) ensuring reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values using SimpleImputer (replace NaNs with the median)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}, Testing set size: {X_test.shape}\")\n",
    "\n",
    "# Define the Optuna optimization function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),  # L2 regularization\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train the model with early stopping to prevent overfitting\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=20, verbose=False)\n",
    "    \n",
    "    # Make predictions and clip values between 0 and 1\n",
    "    y_pred = np.clip(model.predict(X_test), 0, 1)\n",
    "    \n",
    "    # Return Mean Squared Error (MSE) for evaluation\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Run Optuna to optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)  # Increased trials for better optimization\n",
    "\n",
    "# Retrieve the best hyperparameters found by Optuna\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "\n",
    "# Train the final model with optimized hyperparameters and early stopping\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=20, verbose=False)\n",
    "\n",
    "# Generate final predictions and ensure values are between 0 and 1\n",
    "y_pred_full = np.clip(best_model.predict(X), 0, 1)\n",
    "pairs_df['WinProbability'] = y_pred_full\n",
    "\n",
    "# Format output to match the required submission format\n",
    "season = 2025  # Adjust the season as needed\n",
    "pairs_df['ID'] = pairs_df.apply(lambda row: f\"{season}_{int(row['TeamID1'])}_{int(row['TeamID2'])}\", axis=1)\n",
    "pairs_df['Pred'] = pairs_df['WinProbability'].round(1)  # Round probabilities to one decimal place\n",
    "submission_df = pairs_df[['ID', 'Pred']]\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv(\"/kaggle/working/submission_m.csv\", index=False)\n",
    "print(\"The file 'submission_m.csv' was created successfully!\")\n",
    "\n",
    "# Calculate and display MSE on both training and test sets\n",
    "y_pred_train = np.clip(best_model.predict(X_train), 0, 1)\n",
    "y_pred_test = np.clip(best_model.predict(X_test), 0, 1)\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error on Training Set: {train_mse:.4f}\")\n",
    "print(f\"Mean Squared Error on Test Set: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6306573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:21.318634Z",
     "iopub.status.busy": "2025-03-03T08:46:21.318243Z",
     "iopub.status.idle": "2025-03-03T08:46:21.367268Z",
     "shell.execute_reply": "2025-03-03T08:46:21.365922Z"
    },
    "papermill": {
     "duration": 0.07379,
     "end_time": "2025-03-03T08:46:21.369335",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.295545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65698</th>\n",
       "      <td>2025_1474_1477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65699</th>\n",
       "      <td>2025_1474_1478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65700</th>\n",
       "      <td>2025_1475_1477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65701</th>\n",
       "      <td>2025_1475_1478</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65702</th>\n",
       "      <td>2025_1477_1478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65703 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Pred\n",
       "0      2025_1101_1102   0.0\n",
       "1      2025_1101_1103   0.0\n",
       "2      2025_1101_1104   0.0\n",
       "3      2025_1101_1105   0.1\n",
       "4      2025_1101_1106   0.0\n",
       "...               ...   ...\n",
       "65698  2025_1474_1477   1.0\n",
       "65699  2025_1474_1478   1.0\n",
       "65700  2025_1475_1477   1.0\n",
       "65701  2025_1475_1478   0.1\n",
       "65702  2025_1477_1478   0.0\n",
       "\n",
       "[65703 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_m = pd.read_csv(\"/kaggle/working/submission_m.csv\") \n",
    "submission_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405c346",
   "metadata": {
    "papermill": {
     "duration": 0.020762,
     "end_time": "2025-03-03T08:46:21.412049",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.391287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ensure that there are no empty values ​​in the prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4960d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:21.454387Z",
     "iopub.status.busy": "2025-03-03T08:46:21.453922Z",
     "iopub.status.idle": "2025-03-03T08:46:21.637362Z",
     "shell.execute_reply": "2025-03-03T08:46:21.635928Z"
    },
    "papermill": {
     "duration": 0.207128,
     "end_time": "2025-03-03T08:46:21.639413",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.432285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty values in ID: 0\n",
      "Number of empty values ​​in TeamID1: 0\n",
      "Number of empty values ​​in TeamID2: 0\n",
      "\n",
      "There are no empty values in ID, TeamID1, or TeamID2.\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "submission_m = pd.read_csv('/kaggle/working/submission_m.csv')\n",
    "\n",
    "# Check for blank values in ID column\n",
    "missing_id = submission_m['ID'].isna().sum()\n",
    "print(f\"Number of empty values in ID: {missing_id}\")\n",
    "\n",
    "# Extract TeamID1 and TeamID2 from ID\n",
    "submission_m[['Season', 'TeamID1', 'TeamID2']] = submission_m['ID'].str.split('_', expand=True)\n",
    "\n",
    "# Check for empty values in TeamID1 and TeamID2\n",
    "missing_teamid1 = submission_m['TeamID1'].isna().sum()\n",
    "missing_teamid2 = submission_m['TeamID2'].isna().sum()\n",
    "\n",
    "print(f\"Number of empty values ​​in TeamID1: {missing_teamid1}\")\n",
    "print(f\"Number of empty values ​​in TeamID2: {missing_teamid2}\")\n",
    "\n",
    "# If there are no empty values\n",
    "if missing_id == 0 and missing_teamid1 == 0 and missing_teamid2 == 0:\n",
    "    print(\"\\nThere are no empty values in ID, TeamID1, or TeamID2.\")\n",
    "else:\n",
    "    print(\"\\nThere are blank values in some columns, check the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52043c2b",
   "metadata": {
    "papermill": {
     "duration": 0.020629,
     "end_time": "2025-03-03T08:46:21.681173",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.660544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a553d0",
   "metadata": {
    "papermill": {
     "duration": 0.021419,
     "end_time": "2025-03-03T08:46:21.813389",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.791970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stage 2: Analyze women’s match data and create a prediction model for women’s teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01af7f",
   "metadata": {
    "papermill": {
     "duration": 0.020762,
     "end_time": "2025-03-03T08:46:21.855503",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.834741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating the win rate for each team in women's conference tournament games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce5bcff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:21.899720Z",
     "iopub.status.busy": "2025-03-03T08:46:21.899336Z",
     "iopub.status.idle": "2025-03-03T08:46:21.939569Z",
     "shell.execute_reply": "2025-03-03T08:46:21.938318Z"
    },
    "papermill": {
     "duration": 0.06519,
     "end_time": "2025-03-03T08:46:21.941741",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.876551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TotalGames</th>\n",
       "      <th>ConferenceWins</th>\n",
       "      <th>TeamConferenceWinRate</th>\n",
       "      <th>IsConferenceTourney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3101</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3102</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3103</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3104</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3105</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamID  TotalGames  ConferenceWins  TeamConferenceWinRate  \\\n",
       "0    3101          10               5               0.500000   \n",
       "1    3102          29               6               0.206897   \n",
       "2    3103          30              11               0.366667   \n",
       "3    3104          31               8               0.258065   \n",
       "4    3105          24               4               0.166667   \n",
       "\n",
       "   IsConferenceTourney  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load conference tournament game data\n",
    "conference_games_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WConferenceTourneyGames.csv')\n",
    "\n",
    "# Extract winning teams and mark them with \"Win = 1\"\n",
    "conference_games_wins_w = conference_games_w[['WTeamID']].copy()\n",
    "conference_games_wins_w['Win'] = 1\n",
    "conference_games_wins_w.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Extract losing teams and mark them with \"Win = 0\"\n",
    "conference_games_losses_w = conference_games_w[['LTeamID']].copy()\n",
    "conference_games_losses_w['Win'] = 0\n",
    "conference_games_losses_w.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Combine winning and losing teams into one dataset, ensuring each team has its match record\n",
    "conference_team_stats_w = pd.concat([conference_games_wins_w, conference_games_losses_w])\n",
    "\n",
    "# Compute total games played and number of wins per team\n",
    "conference_summary_w = (\n",
    "    conference_team_stats_w.groupby('TeamID')\n",
    "    .agg(TotalGames=('Win', 'count'), ConferenceWins=('Win', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure there are no division errors by replacing NaN values with 0\n",
    "conference_summary_w['TotalGames'] = conference_summary_w['TotalGames'].fillna(0)\n",
    "conference_summary_w['ConferenceWins'] = conference_summary_w['ConferenceWins'].fillna(0)\n",
    "\n",
    "# Compute win rate while avoiding division by zero\n",
    "conference_summary_w['TeamConferenceWinRate'] = (\n",
    "    conference_summary_w['ConferenceWins'] / conference_summary_w['TotalGames']\n",
    ").fillna(0)  # In case any division by zero occurs, replace NaN with 0\n",
    "\n",
    "# Add a feature that specifies that this data is for a conference tournament\n",
    "conference_summary_w['IsConferenceTourney'] = 1\n",
    "\n",
    "# Save the extracted conference statistics\n",
    "conference_summary_w.to_csv('/kaggle/working/conference_summary_w.csv', index=False)\n",
    "\n",
    "# Show preliminary results\n",
    "conference_summary_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e8de2",
   "metadata": {
    "papermill": {
     "duration": 0.022706,
     "end_time": "2025-03-03T08:46:21.986194",
     "exception": false,
     "start_time": "2025-03-03T08:46:21.963488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculate the win rate for each team and the average point difference in the tournament under pressure for women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6c13c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:22.031707Z",
     "iopub.status.busy": "2025-03-03T08:46:22.031318Z",
     "iopub.status.idle": "2025-03-03T08:46:22.069267Z",
     "shell.execute_reply": "2025-03-03T08:46:22.067519Z"
    },
    "papermill": {
     "duration": 0.063329,
     "end_time": "2025-03-03T08:46:22.071275",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.007946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  TournamentWinRate  AvgTournamentScoreDiff\n",
      "0    3101              0.000                     0.0\n",
      "1    3103              0.000                     0.0\n",
      "2    3104              0.500                    15.6\n",
      "3    3106              0.000                     0.0\n",
      "4    3107              0.125                     2.0\n"
     ]
    }
   ],
   "source": [
    "# Download tournament match data under pressure\n",
    "tourney_results_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyCompactResults.csv')\n",
    "\n",
    "# Calculate the tournament win rate for each team:\n",
    "# 1- Calculate the number of wins for each winning team.\n",
    "tourney_wins_w = tourney_results_w.groupby('WTeamID').size().reset_index(name='TournamentWins')\n",
    "tourney_wins_w.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# 2- Calculate the number of losses for each losing team.\n",
    "tourney_losses_w = tourney_results_w.groupby('LTeamID').size().reset_index(name='TournamentLosses')\n",
    "tourney_losses_w.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# 3- Merge win and loss data and ensure no NaN values.\n",
    "tourney_stats_w = pd.merge(tourney_wins_w, tourney_losses_w, on='TeamID', how='outer').fillna(0)\n",
    "\n",
    "# 4- Ensure correct data types\n",
    "tourney_stats_w['TournamentWins'] = tourney_stats_w['TournamentWins'].astype(int)\n",
    "tourney_stats_w['TournamentLosses'] = tourney_stats_w['TournamentLosses'].astype(int)\n",
    "\n",
    "# 5- Calculating the winning rate in the tournament.\n",
    "tourney_stats_w['TournamentWinRate'] = tourney_stats_w['TournamentWins'] / (\n",
    "    tourney_stats_w['TournamentWins'] + tourney_stats_w['TournamentLosses']\n",
    ")\n",
    "\n",
    "# Calculate the average points difference in the tournament\n",
    "tourney_results_w['ScoreDiff'] = tourney_results_w['WScore'] - tourney_results_w['LScore']\n",
    "score_diff_w = tourney_results_w.groupby('WTeamID')['ScoreDiff'].mean().reset_index()\n",
    "score_diff_w.rename(columns={'WTeamID': 'TeamID', 'ScoreDiff': 'AvgTournamentScoreDiff'}, inplace=True)\n",
    "\n",
    "# Merge extracted features while ensuring no NaN values\n",
    "tourney_features_w = pd.merge(tourney_stats_w, score_diff_w, on='TeamID', how='left')\n",
    "\n",
    "# Replace missing values in the score difference with zero to ensure there is no NaN.\n",
    "tourney_features_w['AvgTournamentScoreDiff'] = tourney_features_w['AvgTournamentScoreDiff'].fillna(0)\n",
    "\n",
    "# Save feature file\n",
    "tourney_features_w.to_csv('/kaggle/working/tourney_features_w.csv', index=False)\n",
    "\n",
    "# Preview final results\n",
    "print(tourney_features_w[['TeamID', 'TournamentWinRate', 'AvgTournamentScoreDiff']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55b7e5",
   "metadata": {
    "papermill": {
     "duration": 0.021779,
     "end_time": "2025-03-03T08:46:22.115900",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.094121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating the successful shooting percentage for each team and the extra time rate from the detailed results of the women's tournaments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94969208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:22.160848Z",
     "iopub.status.busy": "2025-03-03T08:46:22.160426Z",
     "iopub.status.idle": "2025-03-03T08:46:22.192252Z",
     "shell.execute_reply": "2025-03-03T08:46:22.190856Z"
    },
    "papermill": {
     "duration": 0.056768,
     "end_time": "2025-03-03T08:46:22.194446",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.137678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  AvgFieldGoalPercentage  AvgOTGames\n",
      "0    3101                0.450000         0.0\n",
      "1    3103                0.450000         0.0\n",
      "2    3104                0.463703         0.0\n",
      "3    3106                0.450000         0.0\n",
      "4    3107                0.456250         0.0\n"
     ]
    }
   ],
   "source": [
    "# Load detailed tournament results data\n",
    "tourney_detailed_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyDetailedResults.csv')\n",
    "\n",
    "# Create a copy for the winning teams containing team ID, field goals made (FGM), field goals attempted (FGA), and number of overtime games (NumOT)\n",
    "winners_w = tourney_detailed_w[['WTeamID', 'WFGM', 'WFGA', 'NumOT']].copy()\n",
    "winners_w.rename(columns={'WTeamID': 'TeamID', 'WFGM': 'FGM', 'WFGA': 'FGA'}, inplace=True)\n",
    "\n",
    "# Create a copy for the losing teams containing team ID, points scored (used as FGM approximation), and number of overtime games\n",
    "losers_w = tourney_detailed_w[['LTeamID', 'LScore', 'NumOT']].copy()\n",
    "losers_w.rename(columns={'LTeamID': 'TeamID', 'LScore': 'FGM'}, inplace=True)\n",
    "\n",
    "# Estimate field goal attempts for losing teams using an assumed 45% shooting percentage\n",
    "losers_w['FGA'] = losers_w['FGM'] / 0.45  # Estimated based on general shooting accuracy\n",
    "\n",
    "# Merge winners and losers into a single dataset\n",
    "teams_shots_w = pd.concat([winners_w, losers_w], ignore_index=True)\n",
    "\n",
    "# Handle missing or invalid values in FGA before calculating FG%\n",
    "teams_shots_w['FGA'] = teams_shots_w['FGA'].fillna(1)  # Replace NaN with 1 to avoid division errors\n",
    "teams_shots_w['FGA'] = teams_shots_w['FGA'].clip(lower=1)  # Ensure FGA is at least 1 to prevent division issues\n",
    "\n",
    "# Compute field goal percentage (FG%)\n",
    "teams_shots_w['FG%'] = teams_shots_w['FGM'] / teams_shots_w['FGA']\n",
    "\n",
    "# Fill missing values in NumOT\n",
    "teams_shots_w['NumOT'] = teams_shots_w['NumOT'].fillna(0)\n",
    "\n",
    "# Calculate the average field goal percentage per team\n",
    "fg_percentage_w = teams_shots_w.groupby('TeamID')['FG%'].mean().reset_index().rename(columns={'FG%': 'AvgFieldGoalPercentage'})\n",
    "\n",
    "# Calculate the average number of overtime games per team\n",
    "ot_games_w = teams_shots_w.groupby('TeamID')['NumOT'].mean().reset_index().rename(columns={'NumOT': 'AvgOTGames'})\n",
    "\n",
    "# Merge the extracted features\n",
    "detailed_features_w = fg_percentage_w.merge(ot_games_w, on='TeamID', how='left')\n",
    "\n",
    "# Save the features to a CSV file\n",
    "detailed_features_w.to_csv('/kaggle/working/detailed_features_w.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(detailed_features_w.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c33624",
   "metadata": {
    "papermill": {
     "duration": 0.021777,
     "end_time": "2025-03-03T08:46:22.238769",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.216992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating Win Rate and Average Points Difference in Regular Season Under Pressure for women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47373ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:22.283843Z",
     "iopub.status.busy": "2025-03-03T08:46:22.283383Z",
     "iopub.status.idle": "2025-03-03T08:46:22.437887Z",
     "shell.execute_reply": "2025-03-03T08:46:22.436218Z"
    },
    "papermill": {
     "duration": 0.179493,
     "end_time": "2025-03-03T08:46:22.439721",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.260228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  SeasonWins  SeasonLosses  SeasonWinRate  AvgSeasonScoreDiff\n",
      "0    3101         174           126       0.580000            1.283935\n",
      "1    3102         165           611       0.212629           -3.935367\n",
      "2    3103         317           484       0.395755           -1.825544\n",
      "3    3104         428           397       0.518788            1.137191\n",
      "4    3105         296           446       0.398922           -2.501129\n"
     ]
    }
   ],
   "source": [
    "# Load Regular Season Results Data\n",
    "season_results_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonCompactResults.csv')\n",
    "\n",
    "# Calculate Regular Season Wins and Losses\n",
    "season_wins_w = season_results_w.groupby('WTeamID').size().reset_index(name='SeasonWins')\n",
    "season_losses_w = season_results_w.groupby('LTeamID').size().reset_index(name='SeasonLosses')\n",
    "\n",
    "# Rename columns to unify TeamID\n",
    "season_wins_w.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "season_losses_w.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Merge wins and losses, replacing NaN with 0\n",
    "season_stats_w = pd.merge(season_wins_w, season_losses_w, on='TeamID', how='outer').fillna(0)\n",
    "\n",
    "# Convert columns to integer type after filling NaN values\n",
    "season_stats_w[['SeasonWins', 'SeasonLosses']] = season_stats_w[['SeasonWins', 'SeasonLosses']].astype(int)\n",
    "\n",
    "# Calculate Season Win Rate (avoid division by zero)\n",
    "season_stats_w['SeasonWinRate'] = np.where(\n",
    "    (season_stats_w['SeasonWins'] + season_stats_w['SeasonLosses']) > 0,\n",
    "    season_stats_w['SeasonWins'] / (season_stats_w['SeasonWins'] + season_stats_w['SeasonLosses']),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Calculate average points difference for both winning and losing teams\n",
    "season_results_w['ScoreDiff'] = season_results_w['WScore'] - season_results_w['LScore']\n",
    "season_results_w['LScoreDiff'] = -season_results_w['ScoreDiff']\n",
    "\n",
    "# Compute mean score difference for winners and losers\n",
    "avg_score_diff_win = season_results_w.groupby('WTeamID')['ScoreDiff'].mean().reset_index()\n",
    "avg_score_diff_loss = season_results_w.groupby('LTeamID')['LScoreDiff'].mean().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "avg_score_diff_win.rename(columns={'WTeamID': 'TeamID', 'ScoreDiff': 'AvgSeasonScoreDiff'}, inplace=True)\n",
    "avg_score_diff_loss.rename(columns={'LTeamID': 'TeamID', 'LScoreDiff': 'AvgSeasonScoreDiff'}, inplace=True)\n",
    "\n",
    "# Combine winners and losers score differences and take the mean per team\n",
    "avg_score_diff_w = pd.concat([avg_score_diff_win, avg_score_diff_loss]).groupby('TeamID')['AvgSeasonScoreDiff'].mean().reset_index()\n",
    "\n",
    "# Merge extracted features\n",
    "season_features_w = season_stats_w.merge(avg_score_diff_w, on='TeamID', how='left')\n",
    "\n",
    "# Replace NaN values in score difference with zero\n",
    "season_features_w['AvgSeasonScoreDiff'] = season_features_w['AvgSeasonScoreDiff'].fillna(0)\n",
    "\n",
    "# Save feature file\n",
    "season_features_w.to_csv('/kaggle/working/season_features_w.csv', index=False)\n",
    "\n",
    "# Data Preview\n",
    "print(season_features_w.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f42d20",
   "metadata": {
    "papermill": {
     "duration": 0.021675,
     "end_time": "2025-03-03T08:46:22.483285",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.461610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating successful shooting percentage and average points conceded for each team from detailed results for the women's regular season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34b93b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:22.528738Z",
     "iopub.status.busy": "2025-03-03T08:46:22.528292Z",
     "iopub.status.idle": "2025-03-03T08:46:22.919535Z",
     "shell.execute_reply": "2025-03-03T08:46:22.918029Z"
    },
    "papermill": {
     "duration": 0.416476,
     "end_time": "2025-03-03T08:46:22.921783",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.505307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  AvgFieldGoalPercentageSeason  AvgPointsAllowed  AvgPointsScored\n",
      "0    3101                      0.461820         66.463333        69.886667\n",
      "1    3102                      0.451757         68.109170        57.288210\n",
      "2    3103                      0.438990         68.294505        68.178022\n",
      "3    3104                      0.445287         64.116910        67.371608\n",
      "4    3105                      0.428845         65.077098        59.725624\n"
     ]
    }
   ],
   "source": [
    "# Load detailed results for the regular season\n",
    "season_detailed_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonDetailedResults.csv')\n",
    "\n",
    "# Extract relevant stats for the winning team (field goals made/attempted, points scored, and points allowed)\n",
    "winners_w = season_detailed_w[['WTeamID', 'WFGM', 'WFGA', 'LScore', 'WScore']].copy()\n",
    "winners_w.rename(columns={'WTeamID': 'TeamID', 'WFGM': 'FGM', 'WFGA': 'FGA', \n",
    "                          'LScore': 'PointsAllowed', 'WScore': 'PointsScored'}, inplace=True)\n",
    "\n",
    "# Extract relevant stats for the losing team (same stats as winners)\n",
    "losers_w = season_detailed_w[['LTeamID', 'LScore', 'WFGM', 'WFGA', 'WScore']].copy()\n",
    "losers_w.rename(columns={'LTeamID': 'TeamID', 'LScore': 'PointsScored', 'WFGM': 'FGM', \n",
    "                         'WFGA': 'FGA', 'WScore': 'PointsAllowed'}, inplace=True)\n",
    "\n",
    "# Combine winners and losers into a single dataset\n",
    "teams_stats_w = pd.concat([winners_w, losers_w], ignore_index=True)\n",
    "\n",
    "# Ensure FGA values are non-negative\n",
    "teams_stats_w['FGA'] = teams_stats_w['FGA'].clip(lower=0)\n",
    "\n",
    "# Calculate field goal percentage (avoiding division by zero)\n",
    "teams_stats_w['FG%'] = np.where(teams_stats_w['FGA'] > 0, teams_stats_w['FGM'] / teams_stats_w['FGA'], 0)\n",
    "\n",
    "# Compute the average field goal percentage for each team\n",
    "fg_percentage_season_w = teams_stats_w.groupby('TeamID')['FG%'].mean().reset_index().rename(\n",
    "    columns={'FG%': 'AvgFieldGoalPercentageSeason'}\n",
    ")\n",
    "\n",
    "# Compute the average points allowed (defensive strength) for each team\n",
    "defensive_strength_w = teams_stats_w.groupby('TeamID')['PointsAllowed'].mean().reset_index().rename(\n",
    "    columns={'PointsAllowed': 'AvgPointsAllowed'}\n",
    ")\n",
    "\n",
    "# Compute the average points scored (offensive strength) for each team\n",
    "offensive_strength_w = teams_stats_w.groupby('TeamID')['PointsScored'].mean().reset_index().rename(\n",
    "    columns={'PointsScored': 'AvgPointsScored'}\n",
    ")\n",
    "\n",
    "# Merge all extracted features into a single dataset\n",
    "season_detailed_features_w = fg_percentage_season_w.merge(defensive_strength_w, on='TeamID', how='left')\n",
    "season_detailed_features_w = season_detailed_features_w.merge(offensive_strength_w, on='TeamID', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "season_detailed_features_w = season_detailed_features_w.fillna(0)\n",
    "\n",
    "# Save the feature dataset\n",
    "season_detailed_features_w.to_csv('/kaggle/working/season_detailed_features_w.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(season_detailed_features_w.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c2796",
   "metadata": {
    "papermill": {
     "duration": 0.02086,
     "end_time": "2025-03-03T08:46:22.964078",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.943218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating win rate and performance difference for each team in a women's secondary game under pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e90b766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:23.008947Z",
     "iopub.status.busy": "2025-03-03T08:46:23.008525Z",
     "iopub.status.idle": "2025-03-03T08:46:23.048855Z",
     "shell.execute_reply": "2025-03-03T08:46:23.047262Z"
    },
    "papermill": {
     "duration": 0.066015,
     "end_time": "2025-03-03T08:46:23.051133",
     "exception": false,
     "start_time": "2025-03-03T08:46:22.985118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  SecondaryTourneyWinRate  SecondaryTourneyPressureWinRate\n",
      "0    3101                 0.166667                         0.000000\n",
      "1    3102                 0.500000                         1.000000\n",
      "2    3103                 0.000000                         0.000000\n",
      "3    3104                 0.692308                         0.666667\n",
      "4    3107                 0.000000                         0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load secondary tournament results\n",
    "file_path = \"/kaggle/input/march-machine-learning-mania-2025/WSecondaryTourneyCompactResults.csv\"\n",
    "secondary_tourney_results_w = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the number of wins and losses in the secondary tournament\n",
    "secondary_tourney_wins_w = secondary_tourney_results_w.groupby('WTeamID').size().reset_index(name='SecondaryTourneyWins')\n",
    "secondary_tourney_losses_w = secondary_tourney_results_w.groupby('LTeamID').size().reset_index(name='SecondaryTourneyLosses')\n",
    "\n",
    "# Rename columns to standardize TeamID across wins and losses\n",
    "secondary_tourney_wins_w.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "secondary_tourney_losses_w.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Merge win and loss statistics for each team\n",
    "secondary_tourney_stats_w = pd.merge(secondary_tourney_wins_w, secondary_tourney_losses_w, on='TeamID', how='outer').fillna(0)\n",
    "\n",
    "# Calculate win rate in the secondary tournament, avoiding division by zero\n",
    "secondary_tourney_stats_w['SecondaryTourneyWinRate'] = np.where(\n",
    "    (secondary_tourney_stats_w['SecondaryTourneyWins'] + secondary_tourney_stats_w['SecondaryTourneyLosses']) > 0,\n",
    "    secondary_tourney_stats_w['SecondaryTourneyWins'] / (secondary_tourney_stats_w['SecondaryTourneyWins'] + secondary_tourney_stats_w['SecondaryTourneyLosses']),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Identify games played under pressure (either in overtime or with a score difference of 5 points or less)\n",
    "secondary_tourney_results_w['ScoreDiff'] = secondary_tourney_results_w['WScore'] - secondary_tourney_results_w['LScore']\n",
    "pressure_games_w = secondary_tourney_results_w[\n",
    "    (secondary_tourney_results_w['NumOT'] > 0) | (secondary_tourney_results_w['ScoreDiff'].abs() <= 5)\n",
    "]\n",
    "\n",
    "# Calculate the number of wins and losses in pressure situations\n",
    "pressure_wins_w = pressure_games_w.groupby('WTeamID').size().reset_index(name='PressureWins')\n",
    "pressure_losses_w = pressure_games_w.groupby('LTeamID').size().reset_index(name='PressureLosses')\n",
    "\n",
    "# Rename columns to standardize TeamID across wins and losses in pressure games\n",
    "pressure_wins_w.rename(columns={'WTeamID': 'TeamID'}, inplace=True)\n",
    "pressure_losses_w.rename(columns={'LTeamID': 'TeamID'}, inplace=True)\n",
    "\n",
    "# Merge pressure game statistics\n",
    "pressure_stats_w = pd.merge(pressure_wins_w, pressure_losses_w, on='TeamID', how='outer').fillna(0)\n",
    "\n",
    "# Calculate win rate under pressure, avoiding division by zero\n",
    "pressure_stats_w['SecondaryTourneyPressureWinRate'] = np.where(\n",
    "    (pressure_stats_w['PressureWins'] + pressure_stats_w['PressureLosses']) > 0,\n",
    "    pressure_stats_w['PressureWins'] / (pressure_stats_w['PressureWins'] + pressure_stats_w['PressureLosses']),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Merge secondary tournament statistics with pressure game statistics\n",
    "secondary_tourney_features_w = pd.merge(\n",
    "    secondary_tourney_stats_w[['TeamID', 'SecondaryTourneyWinRate']],\n",
    "    pressure_stats_w[['TeamID', 'SecondaryTourneyPressureWinRate']],\n",
    "    on='TeamID',\n",
    "    how='left'\n",
    ").fillna(0)\n",
    "\n",
    "# Save the final dataset with extracted features\n",
    "secondary_tourney_features_w.to_csv('/kaggle/working/secondary_tourney_features_w.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(secondary_tourney_features_w.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e2252",
   "metadata": {
    "papermill": {
     "duration": 0.020662,
     "end_time": "2025-03-03T08:46:23.092991",
     "exception": false,
     "start_time": "2025-03-03T08:46:23.072329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Merge all extracted feature files for women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f847dd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:23.138513Z",
     "iopub.status.busy": "2025-03-03T08:46:23.138094Z",
     "iopub.status.idle": "2025-03-03T08:46:23.203786Z",
     "shell.execute_reply": "2025-03-03T08:46:23.202223Z"
    },
    "papermill": {
     "duration": 0.091519,
     "end_time": "2025-03-03T08:46:23.206421",
     "exception": false,
     "start_time": "2025-03-03T08:46:23.114902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conference_summary_w.csv: 361 unique teams\n",
      "tourney_features_w.csv: 279 unique teams\n",
      "detailed_features_w.csv: 225 unique teams\n",
      "season_features_w.csv: 369 unique teams\n",
      "season_detailed_features_w.csv: 366 unique teams\n",
      "secondary_tourney_features_w.csv: 285 unique teams\n",
      "Missing values before filling: TeamID                               0\n",
      "TeamConferenceWinRate                0\n",
      "TournamentWinRate                   83\n",
      "AvgTournamentScoreDiff              83\n",
      "AvgFieldGoalPercentage             136\n",
      "AvgOTGames                         136\n",
      "SeasonWinRate                        0\n",
      "AvgSeasonScoreDiff                   0\n",
      "AvgFieldGoalPercentageSeason         1\n",
      "AvgPointsAllowed                     1\n",
      "AvgPointsScored                      1\n",
      "SecondaryTourneyWinRate             76\n",
      "SecondaryTourneyPressureWinRate     76\n",
      "dtype: int64\n",
      "Missing values after filling: TeamID                             0\n",
      "TeamConferenceWinRate              0\n",
      "TournamentWinRate                  0\n",
      "AvgTournamentScoreDiff             0\n",
      "AvgFieldGoalPercentage             0\n",
      "AvgOTGames                         0\n",
      "SeasonWinRate                      0\n",
      "AvgSeasonScoreDiff                 0\n",
      "AvgFieldGoalPercentageSeason       0\n",
      "AvgPointsAllowed                   0\n",
      "AvgPointsScored                    0\n",
      "SecondaryTourneyWinRate            0\n",
      "SecondaryTourneyPressureWinRate    0\n",
      "dtype: int64\n",
      "   TeamID  TeamConferenceWinRate  TournamentWinRate  AvgTournamentScoreDiff  \\\n",
      "0    3101               0.500000           0.000000                0.000000   \n",
      "1    3102               0.206897           0.208687                5.931126   \n",
      "2    3103               0.366667           0.000000                0.000000   \n",
      "3    3104               0.258065           0.500000               15.600000   \n",
      "4    3105               0.166667           0.208687                5.931126   \n",
      "\n",
      "   AvgFieldGoalPercentage  AvgOTGames  SeasonWinRate  AvgSeasonScoreDiff  \\\n",
      "0                0.450000     0.00000       0.580000            1.283935   \n",
      "1                0.450167     0.02309       0.212629           -3.935367   \n",
      "2                0.450000     0.00000       0.395755           -1.825544   \n",
      "3                0.463703     0.00000       0.518788            1.137191   \n",
      "4                0.450167     0.02309       0.398922           -2.501129   \n",
      "\n",
      "   AvgFieldGoalPercentageSeason  AvgPointsAllowed  AvgPointsScored  \\\n",
      "0                      0.461820         66.463333        69.886667   \n",
      "1                      0.451757         68.109170        57.288210   \n",
      "2                      0.438990         68.294505        68.178022   \n",
      "3                      0.445287         64.116910        67.371608   \n",
      "4                      0.428845         65.077098        59.725624   \n",
      "\n",
      "   SecondaryTourneyWinRate  SecondaryTourneyPressureWinRate  \n",
      "0                 0.166667                         0.000000  \n",
      "1                 0.500000                         1.000000  \n",
      "2                 0.000000                         0.000000  \n",
      "3                 0.692308                         0.666667  \n",
      "4                 0.376126                         0.301579  \n"
     ]
    }
   ],
   "source": [
    "# Load extracted feature files efficiently\n",
    "def load_feature_file(filename, columns):\n",
    "    return pd.read_csv(filename, usecols=columns)\n",
    "\n",
    "# Define required columns for each file\n",
    "feature_files = {\n",
    "    'conference_summary_w.csv': ['TeamID', 'TeamConferenceWinRate'],\n",
    "    'tourney_features_w.csv': ['TeamID', 'TournamentWinRate', 'AvgTournamentScoreDiff'],\n",
    "    'detailed_features_w.csv': ['TeamID', 'AvgFieldGoalPercentage', 'AvgOTGames'],\n",
    "    'season_features_w.csv': ['TeamID', 'SeasonWinRate', 'AvgSeasonScoreDiff'],\n",
    "    'season_detailed_features_w.csv': ['TeamID', 'AvgFieldGoalPercentageSeason', 'AvgPointsAllowed', 'AvgPointsScored'],\n",
    "    'secondary_tourney_features_w.csv': ['TeamID', 'SecondaryTourneyWinRate', 'SecondaryTourneyPressureWinRate']\n",
    "}\n",
    "\n",
    "# Load and merge feature data\n",
    "merged_df_w = None\n",
    "for file, cols in feature_files.items():\n",
    "    df = load_feature_file(file, cols)\n",
    "    merged_df_w = df if merged_df_w is None else merged_df_w.merge(df, on='TeamID', how='left')\n",
    "\n",
    "# Check the number of unique teams in each file\n",
    "for file_name, cols in feature_files.items():\n",
    "    df = load_feature_file(file_name, cols)\n",
    "    print(f\"{file_name}: {df['TeamID'].nunique()} unique teams\")\n",
    "\n",
    "# Print missing values before filling\n",
    "print(\"Missing values before filling:\", merged_df_w.isna().sum())\n",
    "\n",
    "# Fill missing values with column mean, then replace any remaining NaN with 0\n",
    "merged_df_w.fillna(merged_df_w.mean(numeric_only=True), inplace=True)\n",
    "merged_df_w.fillna(0, inplace=True)\n",
    "\n",
    "# Print missing values after filling\n",
    "print(\"Missing values after filling:\", merged_df_w.isna().sum())\n",
    "\n",
    "# Save the merged file\n",
    "merged_df_w.to_csv('/kaggle/working/merged_team_features_w.csv', index=False)\n",
    "\n",
    "# Show preliminary results\n",
    "print(merged_df_w.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf7215",
   "metadata": {
    "papermill": {
     "duration": 0.021224,
     "end_time": "2025-03-03T08:46:23.249745",
     "exception": false,
     "start_time": "2025-03-03T08:46:23.228521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create all possible combinations of teams so that each pair consists of two different women's teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95245f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:23.293859Z",
     "iopub.status.busy": "2025-03-03T08:46:23.293373Z",
     "iopub.status.idle": "2025-03-03T08:46:26.161562Z",
     "shell.execute_reply": "2025-03-03T08:46:26.160147Z"
    },
    "papermill": {
     "duration": 2.892896,
     "end_time": "2025-03-03T08:46:26.163737",
     "exception": false,
     "start_time": "2025-03-03T08:46:23.270841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file team_pairs_diff_w.csv was created successfully!\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Load merged features\n",
    "file_path = \"/kaggle/working/merged_team_features_w.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract all possible team pairs efficiently\n",
    "team_pairs_w = combinations(df['TeamID'], 2)\n",
    "\n",
    "# Create a DataFrame to store the differences\n",
    "columns_w = ['TeamID1', 'TeamID2'] + [f'{col}_diff' for col in df.columns if col != 'TeamID'] + ['WinProbability']\n",
    "pairs_df_w = []\n",
    "\n",
    "# Convert df to a dictionary with TeamID as index for faster lookups\n",
    "df_dict = df.set_index('TeamID').to_dict(orient='index')\n",
    "\n",
    "# Process team pairs\n",
    "for team1, team2 in team_pairs_w:\n",
    "    team1_data_w = df_dict[team1]\n",
    "    team2_data_w = df_dict[team2]\n",
    "\n",
    "    row = {\n",
    "        'TeamID1': team1,\n",
    "        'TeamID2': team2,\n",
    "    }\n",
    "\n",
    "    feature_diffs_w = []\n",
    "    for col in df.columns:\n",
    "        if col != 'TeamID':\n",
    "            diff = team1_data_w[col] - team2_data_w[col]\n",
    "            row[f'{col}_diff'] = diff\n",
    "            feature_diffs_w.append(diff)\n",
    "\n",
    "    # Compute win probability using sigmoid function\n",
    "    row['WinProbability'] = round(1 / (1 + np.exp(-sum(feature_diffs_w))), 2)\n",
    "\n",
    "    pairs_df_w.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "pairs_df_w = pd.DataFrame(pairs_df_w, columns=columns_w)\n",
    "\n",
    "# Save to CSV\n",
    "pairs_df_w.to_csv(\"/kaggle/working/team_pairs_diff_w.csv\", index=False)\n",
    "\n",
    "print(\"The file team_pairs_diff_w.csv was created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d86bce3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:26.211577Z",
     "iopub.status.busy": "2025-03-03T08:46:26.211165Z",
     "iopub.status.idle": "2025-03-03T08:46:26.452711Z",
     "shell.execute_reply": "2025-03-03T08:46:26.451429Z"
    },
    "papermill": {
     "duration": 0.26752,
     "end_time": "2025-03-03T08:46:26.454585",
     "exception": false,
     "start_time": "2025-03-03T08:46:26.187065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID1</th>\n",
       "      <th>TeamID2</th>\n",
       "      <th>TeamConferenceWinRate_diff</th>\n",
       "      <th>TournamentWinRate_diff</th>\n",
       "      <th>AvgTournamentScoreDiff_diff</th>\n",
       "      <th>AvgFieldGoalPercentage_diff</th>\n",
       "      <th>AvgOTGames_diff</th>\n",
       "      <th>SeasonWinRate_diff</th>\n",
       "      <th>AvgSeasonScoreDiff_diff</th>\n",
       "      <th>AvgFieldGoalPercentageSeason_diff</th>\n",
       "      <th>AvgPointsAllowed_diff</th>\n",
       "      <th>AvgPointsScored_diff</th>\n",
       "      <th>SecondaryTourneyWinRate_diff</th>\n",
       "      <th>SecondaryTourneyPressureWinRate_diff</th>\n",
       "      <th>WinProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3101</td>\n",
       "      <td>3102</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>-0.208687</td>\n",
       "      <td>-5.931126</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.02309</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>5.219302</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>-1.645837</td>\n",
       "      <td>12.598457</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.184245</td>\n",
       "      <td>3.109479</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-1.831172</td>\n",
       "      <td>1.708645</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3101</td>\n",
       "      <td>3104</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-15.600000</td>\n",
       "      <td>-0.013703</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.146744</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>2.346423</td>\n",
       "      <td>2.515059</td>\n",
       "      <td>-0.525641</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3101</td>\n",
       "      <td>3105</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.208687</td>\n",
       "      <td>-5.931126</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.02309</td>\n",
       "      <td>0.181078</td>\n",
       "      <td>3.785064</td>\n",
       "      <td>0.032975</td>\n",
       "      <td>1.386236</td>\n",
       "      <td>10.161043</td>\n",
       "      <td>-0.209459</td>\n",
       "      <td>-0.301579</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3101</td>\n",
       "      <td>3106</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.133385</td>\n",
       "      <td>5.121274</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.384148</td>\n",
       "      <td>11.990739</td>\n",
       "      <td>-0.209459</td>\n",
       "      <td>-0.301579</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64975</th>\n",
       "      <td>3475</td>\n",
       "      <td>3477</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.228298</td>\n",
       "      <td>3.629273</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>-7.035372</td>\n",
       "      <td>2.843837</td>\n",
       "      <td>0.123874</td>\n",
       "      <td>0.198421</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64976</th>\n",
       "      <td>3475</td>\n",
       "      <td>3478</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.196886</td>\n",
       "      <td>6.466232</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>-0.058608</td>\n",
       "      <td>12.825549</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64977</th>\n",
       "      <td>3476</td>\n",
       "      <td>3477</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.077495</td>\n",
       "      <td>0.307895</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>-4.616094</td>\n",
       "      <td>-7.112004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64978</th>\n",
       "      <td>3476</td>\n",
       "      <td>3478</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.108907</td>\n",
       "      <td>3.144854</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>2.360670</td>\n",
       "      <td>2.869709</td>\n",
       "      <td>0.376126</td>\n",
       "      <td>0.301579</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64979</th>\n",
       "      <td>3477</td>\n",
       "      <td>3478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.031411</td>\n",
       "      <td>2.836959</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>6.976764</td>\n",
       "      <td>9.981713</td>\n",
       "      <td>0.376126</td>\n",
       "      <td>0.301579</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64980 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TeamID1  TeamID2  TeamConferenceWinRate_diff  TournamentWinRate_diff  \\\n",
       "0         3101     3102                    0.293103               -0.208687   \n",
       "1         3101     3103                    0.133333                0.000000   \n",
       "2         3101     3104                    0.241935               -0.500000   \n",
       "3         3101     3105                    0.333333               -0.208687   \n",
       "4         3101     3106                   -0.050000                0.000000   \n",
       "...        ...      ...                         ...                     ...   \n",
       "64975     3475     3477                    0.333333                0.000000   \n",
       "64976     3475     3478                    0.333333                0.000000   \n",
       "64977     3476     3477                   -0.666667                0.000000   \n",
       "64978     3476     3478                   -0.666667                0.000000   \n",
       "64979     3477     3478                    0.000000                0.000000   \n",
       "\n",
       "       AvgTournamentScoreDiff_diff  AvgFieldGoalPercentage_diff  \\\n",
       "0                        -5.931126                    -0.000167   \n",
       "1                         0.000000                     0.000000   \n",
       "2                       -15.600000                    -0.013703   \n",
       "3                        -5.931126                    -0.000167   \n",
       "4                         0.000000                     0.000000   \n",
       "...                            ...                          ...   \n",
       "64975                     0.000000                     0.000000   \n",
       "64976                     0.000000                     0.000000   \n",
       "64977                     0.000000                     0.000000   \n",
       "64978                     0.000000                     0.000000   \n",
       "64979                     0.000000                     0.000000   \n",
       "\n",
       "       AvgOTGames_diff  SeasonWinRate_diff  AvgSeasonScoreDiff_diff  \\\n",
       "0             -0.02309            0.367371                 5.219302   \n",
       "1              0.00000            0.184245                 3.109479   \n",
       "2              0.00000            0.061212                 0.146744   \n",
       "3             -0.02309            0.181078                 3.785064   \n",
       "4              0.00000            0.133385                 5.121274   \n",
       "...                ...                 ...                      ...   \n",
       "64975          0.00000            0.228298                 3.629273   \n",
       "64976          0.00000            0.196886                 6.466232   \n",
       "64977          0.00000           -0.077495                 0.307895   \n",
       "64978          0.00000           -0.108907                 3.144854   \n",
       "64979          0.00000           -0.031411                 2.836959   \n",
       "\n",
       "       AvgFieldGoalPercentageSeason_diff  AvgPointsAllowed_diff  \\\n",
       "0                               0.010063              -1.645837   \n",
       "1                               0.022830              -1.831172   \n",
       "2                               0.016533               2.346423   \n",
       "3                               0.032975               1.386236   \n",
       "4                               0.040375               0.384148   \n",
       "...                                  ...                    ...   \n",
       "64975                           0.008936              -7.035372   \n",
       "64976                           0.010726              -0.058608   \n",
       "64977                           0.009789              -4.616094   \n",
       "64978                           0.011579               2.360670   \n",
       "64979                           0.001790               6.976764   \n",
       "\n",
       "       AvgPointsScored_diff  SecondaryTourneyWinRate_diff  \\\n",
       "0                 12.598457                     -0.333333   \n",
       "1                  1.708645                      0.166667   \n",
       "2                  2.515059                     -0.525641   \n",
       "3                 10.161043                     -0.209459   \n",
       "4                 11.990739                     -0.209459   \n",
       "...                     ...                           ...   \n",
       "64975              2.843837                      0.123874   \n",
       "64976             12.825549                      0.500000   \n",
       "64977             -7.112004                      0.000000   \n",
       "64978              2.869709                      0.376126   \n",
       "64979              9.981713                      0.376126   \n",
       "\n",
       "       SecondaryTourneyPressureWinRate_diff  WinProbability  \n",
       "0                                 -1.000000            1.00  \n",
       "1                                  0.000000            0.97  \n",
       "2                                 -0.666667            0.00  \n",
       "3                                 -0.301579            1.00  \n",
       "4                                 -0.301579            1.00  \n",
       "...                                     ...             ...  \n",
       "64975                              0.198421            0.58  \n",
       "64976                              0.500000            1.00  \n",
       "64977                              0.000000            0.00  \n",
       "64978                              0.301579            1.00  \n",
       "64979                              0.301579            1.00  \n",
       "\n",
       "[64980 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_pairs_diff_w = pd.read_csv(\"/kaggle/working/team_pairs_diff_w.csv\")\n",
    "team_pairs_diff_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de868a99",
   "metadata": {
    "papermill": {
     "duration": 0.024003,
     "end_time": "2025-03-03T08:46:26.502312",
     "exception": false,
     "start_time": "2025-03-03T08:46:26.478309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model for predicting the probability of the team with the smallest ID for women winning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ce13c",
   "metadata": {
    "papermill": {
     "duration": 0.022035,
     "end_time": "2025-03-03T08:46:26.546786",
     "exception": false,
     "start_time": "2025-03-03T08:46:26.524751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2028957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:46:26.593564Z",
     "iopub.status.busy": "2025-03-03T08:46:26.593113Z",
     "iopub.status.idle": "2025-03-03T08:50:24.652261Z",
     "shell.execute_reply": "2025-03-03T08:50:24.649901Z"
    },
    "papermill": {
     "duration": 238.085787,
     "end_time": "2025-03-03T08:50:24.655063",
     "exception": false,
     "start_time": "2025-03-03T08:46:26.569276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-03 08:46:26,723] A new study created in memory with name: no-name-f6f063ee-aa7b-482e-96ac-b4a803314def\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (51984, 12), Testing set size: (12996, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:28,552] Trial 0 finished with value: 0.0045203912030867075 and parameters: {'n_estimators': 287, 'learning_rate': 0.1450714306409916, 'max_depth': 6, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309, 'reg_alpha': 1.5599452033620265, 'reg_lambda': 7.464668897345596, 'min_child_weight': 9}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:30,558] Trial 1 finished with value: 0.004801478086382166 and parameters: {'n_estimators': 401, 'learning_rate': 0.12080725777960455, 'max_depth': 5, 'subsample': 0.9909729556485982, 'colsample_bytree': 0.9497327922401265, 'reg_alpha': 2.1233911067827616, 'reg_lambda': 8.454599737656805, 'min_child_weight': 2}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:31,988] Trial 2 finished with value: 0.0057629027219251025 and parameters: {'n_estimators': 252, 'learning_rate': 0.10247564316322377, 'max_depth': 5, 'subsample': 0.7873687420594125, 'colsample_bytree': 0.8835558684167139, 'reg_alpha': 1.3949386065204183, 'reg_lambda': 9.337157188281745, 'min_child_weight': 4}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:33,614] Trial 3 finished with value: 0.005124295376068476 and parameters: {'n_estimators': 328, 'learning_rate': 0.12851759613930136, 'max_depth': 5, 'subsample': 0.8542703315240835, 'colsample_bytree': 0.8777243706586128, 'reg_alpha': 0.46450412719997725, 'reg_lambda': 11.860358815211507, 'min_child_weight': 2}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:34,464] Trial 4 finished with value: 0.005144028774840705 and parameters: {'n_estimators': 132, 'learning_rate': 0.14488855372533332, 'max_depth': 6, 'subsample': 0.9425192044349383, 'colsample_bytree': 0.7913841307520112, 'reg_alpha': 0.9767211400638387, 'reg_lambda': 12.473864212097254, 'min_child_weight': 5}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:35,310] Trial 5 finished with value: 0.007624012809429606 and parameters: {'n_estimators': 161, 'learning_rate': 0.09951769101112701, 'max_depth': 5, 'subsample': 0.9727961206236346, 'colsample_bytree': 0.777633994480005, 'reg_alpha': 6.62522284353982, 'reg_lambda': 9.493688608715289, 'min_child_weight': 6}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:37,481] Trial 6 finished with value: 0.005127007752467997 and parameters: {'n_estimators': 373, 'learning_rate': 0.0684854455525527, 'max_depth': 6, 'subsample': 0.9325398470083344, 'colsample_bytree': 0.9818496824692567, 'reg_alpha': 8.948273504276488, 'reg_lambda': 11.78319983048868, 'min_child_weight': 10}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:38,263] Trial 7 finished with value: 0.008461860060876545 and parameters: {'n_estimators': 144, 'learning_rate': 0.06959828624191453, 'max_depth': 5, 'subsample': 0.7975990992289793, 'colsample_bytree': 0.8166031869068446, 'reg_alpha': 2.713490317738959, 'reg_lambda': 13.629900073215435, 'min_child_weight': 4}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:39,487] Trial 8 finished with value: 0.007689569598859998 and parameters: {'n_estimators': 240, 'learning_rate': 0.10426960831582485, 'max_depth': 5, 'subsample': 0.9406590942262119, 'colsample_bytree': 0.7223651931039312, 'reg_alpha': 9.868869366005173, 'reg_lambda': 13.17795815437326, 'min_child_weight': 2}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:40,190] Trial 9 finished with value: 0.004659211778962821 and parameters: {'n_estimators': 102, 'learning_rate': 0.1315461428454834, 'max_depth': 6, 'subsample': 0.9187021504122962, 'colsample_bytree': 0.9313811040057838, 'reg_alpha': 0.7404465173409036, 'reg_lambda': 9.867725828354182, 'min_child_weight': 2}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:43,522] Trial 10 finished with value: 0.005633435418691882 and parameters: {'n_estimators': 548, 'learning_rate': 0.05059971829558173, 'max_depth': 6, 'subsample': 0.7053885626844458, 'colsample_bytree': 0.7046103211984313, 'reg_alpha': 4.3808092746183, 'reg_lambda': 7.1211538968220545, 'min_child_weight': 10}. Best is trial 0 with value: 0.0045203912030867075.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:48,116] Trial 11 finished with value: 0.003947661130162245 and parameters: {'n_estimators': 492, 'learning_rate': 0.14952949606098453, 'max_depth': 6, 'subsample': 0.8777494817545584, 'colsample_bytree': 0.9116180256445218, 'reg_alpha': 3.950675537099106, 'reg_lambda': 7.433992609029961, 'min_child_weight': 8}. Best is trial 11 with value: 0.003947661130162245.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:51,319] Trial 12 finished with value: 0.0038657642946787227 and parameters: {'n_estimators': 518, 'learning_rate': 0.14990058336990142, 'max_depth': 6, 'subsample': 0.8656078720226557, 'colsample_bytree': 0.8385568170360077, 'reg_alpha': 3.6444230323845614, 'reg_lambda': 7.172514310421252, 'min_child_weight': 8}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:54,334] Trial 13 finished with value: 0.0041704749142175025 and parameters: {'n_estimators': 536, 'learning_rate': 0.1494963955763554, 'max_depth': 6, 'subsample': 0.8090982857180401, 'colsample_bytree': 0.8542668769519566, 'reg_alpha': 4.565433566509627, 'reg_lambda': 14.99489950913241, 'min_child_weight': 8}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:46:57,042] Trial 14 finished with value: 0.004361992006605993 and parameters: {'n_estimators': 465, 'learning_rate': 0.11634064286119826, 'max_depth': 6, 'subsample': 0.8754037808225946, 'colsample_bytree': 0.9189504488595104, 'reg_alpha': 5.893584791362284, 'reg_lambda': 8.1105027004207, 'min_child_weight': 7}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:00,628] Trial 15 finished with value: 0.004033155545158351 and parameters: {'n_estimators': 600, 'learning_rate': 0.13492711431561943, 'max_depth': 6, 'subsample': 0.7496668844156134, 'colsample_bytree': 0.835477555854876, 'reg_alpha': 3.7946242256054403, 'reg_lambda': 10.528574304645993, 'min_child_weight': 8}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:03,523] Trial 16 finished with value: 0.004750344056314068 and parameters: {'n_estimators': 466, 'learning_rate': 0.08515216581332118, 'max_depth': 6, 'subsample': 0.8392499488134854, 'colsample_bytree': 0.9992835457489011, 'reg_alpha': 6.991977116699611, 'reg_lambda': 8.067613684202875, 'min_child_weight': 7}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:06,839] Trial 17 finished with value: 0.00387571985128683 and parameters: {'n_estimators': 451, 'learning_rate': 0.1375162604577373, 'max_depth': 6, 'subsample': 0.889889391119938, 'colsample_bytree': 0.8971435912982684, 'reg_alpha': 3.1608079931904034, 'reg_lambda': 8.657650202003268, 'min_child_weight': 8}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:09,386] Trial 18 finished with value: 0.0039073625491841965 and parameters: {'n_estimators': 406, 'learning_rate': 0.1169475629730764, 'max_depth': 6, 'subsample': 0.9069023275635302, 'colsample_bytree': 0.870033650273758, 'reg_alpha': 3.0529996584262538, 'reg_lambda': 9.009236988855982, 'min_child_weight': 6}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:12,926] Trial 19 finished with value: 0.004763909050014267 and parameters: {'n_estimators': 599, 'learning_rate': 0.13800334606863462, 'max_depth': 6, 'subsample': 0.8333713060780207, 'colsample_bytree': 0.8183612104529064, 'reg_alpha': 5.915176709957256, 'reg_lambda': 10.380824347372426, 'min_child_weight': 9}. Best is trial 12 with value: 0.0038657642946787227.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:15,667] Trial 20 finished with value: 0.003810680431107661 and parameters: {'n_estimators': 434, 'learning_rate': 0.12442731301154356, 'max_depth': 6, 'subsample': 0.7604090862768648, 'colsample_bytree': 0.9575239637233366, 'reg_alpha': 3.0285564775125007, 'reg_lambda': 8.63655455073098, 'min_child_weight': 7}. Best is trial 20 with value: 0.003810680431107661.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:20,145] Trial 21 finished with value: 0.0038639905234791154 and parameters: {'n_estimators': 429, 'learning_rate': 0.12493186077509705, 'max_depth': 6, 'subsample': 0.7642969887583603, 'colsample_bytree': 0.9561307326604095, 'reg_alpha': 3.1689363703675713, 'reg_lambda': 8.619181555448217, 'min_child_weight': 7}. Best is trial 20 with value: 0.003810680431107661.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:23,509] Trial 22 finished with value: 0.003567719405955292 and parameters: {'n_estimators': 518, 'learning_rate': 0.1250586130186664, 'max_depth': 6, 'subsample': 0.756492708339261, 'colsample_bytree': 0.9850519688794689, 'reg_alpha': 2.314107424927481, 'reg_lambda': 7.7581380779590905, 'min_child_weight': 7}. Best is trial 22 with value: 0.003567719405955292.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:26,287] Trial 23 finished with value: 0.0037098455250507787 and parameters: {'n_estimators': 430, 'learning_rate': 0.12296134204123256, 'max_depth': 6, 'subsample': 0.7478721426480025, 'colsample_bytree': 0.9617763092136377, 'reg_alpha': 2.259918068951779, 'reg_lambda': 8.190172104731978, 'min_child_weight': 5}. Best is trial 22 with value: 0.003567719405955292.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:28,540] Trial 24 finished with value: 0.0038579964948672056 and parameters: {'n_estimators': 344, 'learning_rate': 0.11083775131162052, 'max_depth': 6, 'subsample': 0.7114215423996685, 'colsample_bytree': 0.9686426414245648, 'reg_alpha': 1.8240380105885823, 'reg_lambda': 7.87422731134398, 'min_child_weight': 5}. Best is trial 22 with value: 0.003567719405955292.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:31,889] Trial 25 finished with value: 0.003690389631519888 and parameters: {'n_estimators': 501, 'learning_rate': 0.09103969867133103, 'max_depth': 6, 'subsample': 0.7331390049368437, 'colsample_bytree': 0.9872013764250163, 'reg_alpha': 2.2674727852760603, 'reg_lambda': 10.05599689432519, 'min_child_weight': 4}. Best is trial 22 with value: 0.003567719405955292.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:35,014] Trial 26 finished with value: 0.0036523726645823055 and parameters: {'n_estimators': 503, 'learning_rate': 0.08944497642389666, 'max_depth': 6, 'subsample': 0.7332819813570499, 'colsample_bytree': 0.9942522071670691, 'reg_alpha': 2.2554790656842285, 'reg_lambda': 11.216397572265663, 'min_child_weight': 4}. Best is trial 22 with value: 0.003567719405955292.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:38,563] Trial 27 finished with value: 0.0034221892217260494 and parameters: {'n_estimators': 562, 'learning_rate': 0.09010610215854462, 'max_depth': 6, 'subsample': 0.726365107461148, 'colsample_bytree': 0.999857809338148, 'reg_alpha': 0.13897558179016478, 'reg_lambda': 11.443240735991784, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:42,195] Trial 28 finished with value: 0.0034308690026965643 and parameters: {'n_estimators': 546, 'learning_rate': 0.08292870434343459, 'max_depth': 6, 'subsample': 0.7246624330710734, 'colsample_bytree': 0.9380921770725998, 'reg_alpha': 0.6415271592665492, 'reg_lambda': 11.160681151462652, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:45,650] Trial 29 finished with value: 0.003538318679525333 and parameters: {'n_estimators': 569, 'learning_rate': 0.0795227651344094, 'max_depth': 6, 'subsample': 0.7778649001053389, 'colsample_bytree': 0.9358128610121408, 'reg_alpha': 0.004240936620536262, 'reg_lambda': 11.206752780347934, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:49,138] Trial 30 finished with value: 0.0035000629790565836 and parameters: {'n_estimators': 576, 'learning_rate': 0.07619968520386161, 'max_depth': 6, 'subsample': 0.7753377302652827, 'colsample_bytree': 0.9364355759302717, 'reg_alpha': 0.077779659862101, 'reg_lambda': 10.947739433022928, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:54,192] Trial 31 finished with value: 0.003581660871246791 and parameters: {'n_estimators': 567, 'learning_rate': 0.07593072682803559, 'max_depth': 6, 'subsample': 0.7786964326017507, 'colsample_bytree': 0.9356095688095343, 'reg_alpha': 0.06872306788552941, 'reg_lambda': 11.208617702309635, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:47:57,584] Trial 32 finished with value: 0.0035762447075303352 and parameters: {'n_estimators': 562, 'learning_rate': 0.08042157372739268, 'max_depth': 6, 'subsample': 0.7200871700512962, 'colsample_bytree': 0.9379546604081648, 'reg_alpha': 1.277600456014277, 'reg_lambda': 11.74822068043517, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:01,048] Trial 33 finished with value: 0.0037863952024529256 and parameters: {'n_estimators': 575, 'learning_rate': 0.06211597824342682, 'max_depth': 6, 'subsample': 0.8169588098492369, 'colsample_bytree': 0.9068354843556418, 'reg_alpha': 0.18085796019525588, 'reg_lambda': 10.853565299452743, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:04,396] Trial 34 finished with value: 0.004788231279431256 and parameters: {'n_estimators': 588, 'learning_rate': 0.09602807333590033, 'max_depth': 5, 'subsample': 0.7269538200280511, 'colsample_bytree': 0.8896816121836292, 'reg_alpha': 0.012212163436766954, 'reg_lambda': 12.77770079234178, 'min_child_weight': 1}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:07,778] Trial 35 finished with value: 0.0035280156373158544 and parameters: {'n_estimators': 542, 'learning_rate': 0.07737876010117327, 'max_depth': 6, 'subsample': 0.778217066122355, 'colsample_bytree': 0.9412584207410825, 'reg_alpha': 0.9459758851616895, 'reg_lambda': 12.443770704427434, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:11,177] Trial 36 finished with value: 0.003601648252857048 and parameters: {'n_estimators': 535, 'learning_rate': 0.07106059526805511, 'max_depth': 6, 'subsample': 0.793579763004365, 'colsample_bytree': 0.9711099287305114, 'reg_alpha': 1.0775339143565033, 'reg_lambda': 12.300586676267466, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:12,807] Trial 37 finished with value: 0.005618735444925659 and parameters: {'n_estimators': 300, 'learning_rate': 0.08654209054147305, 'max_depth': 5, 'subsample': 0.7365526802741589, 'colsample_bytree': 0.8716636862099991, 'reg_alpha': 0.8117859248544699, 'reg_lambda': 13.90191071464255, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:15,891] Trial 38 finished with value: 0.00386093942867079 and parameters: {'n_estimators': 490, 'learning_rate': 0.06090046441389122, 'max_depth': 6, 'subsample': 0.7020262759418442, 'colsample_bytree': 0.9229420750013171, 'reg_alpha': 1.618724814891654, 'reg_lambda': 12.095488966988317, 'min_child_weight': 2}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:17,867] Trial 39 finished with value: 0.004969319558043672 and parameters: {'n_estimators': 379, 'learning_rate': 0.09428476077963852, 'max_depth': 5, 'subsample': 0.772747395276763, 'colsample_bytree': 0.9749598608698733, 'reg_alpha': 0.690344798749021, 'reg_lambda': 11.59394559718211, 'min_child_weight': 3}. Best is trial 27 with value: 0.0034221892217260494.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:21,424] Trial 40 finished with value: 0.0033983082638388523 and parameters: {'n_estimators': 541, 'learning_rate': 0.10519890844971573, 'max_depth': 6, 'subsample': 0.813988749484424, 'colsample_bytree': 0.9449173821963484, 'reg_alpha': 1.3968705468561469, 'reg_lambda': 12.672390535525942, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:26,474] Trial 41 finished with value: 0.0034655456767794524 and parameters: {'n_estimators': 550, 'learning_rate': 0.10403379224122372, 'max_depth': 6, 'subsample': 0.8186671857835989, 'colsample_bytree': 0.9471845492548316, 'reg_alpha': 1.4616013008583748, 'reg_lambda': 12.958687989084146, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:27,842] Trial 42 finished with value: 0.004106182810793599 and parameters: {'n_estimators': 204, 'learning_rate': 0.10616197041404113, 'max_depth': 6, 'subsample': 0.8108333897545313, 'colsample_bytree': 0.9507310155615766, 'reg_alpha': 1.5584416919506696, 'reg_lambda': 13.08135693803614, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:31,266] Trial 43 finished with value: 0.003623872929716463 and parameters: {'n_estimators': 551, 'learning_rate': 0.09942506875322205, 'max_depth': 6, 'subsample': 0.8339912049241044, 'colsample_bytree': 0.9006345105845532, 'reg_alpha': 0.535762247177778, 'reg_lambda': 13.801178299288177, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:34,453] Trial 44 finished with value: 0.004007964715308513 and parameters: {'n_estimators': 526, 'learning_rate': 0.10919839036060358, 'max_depth': 6, 'subsample': 0.8007491554132771, 'colsample_bytree': 0.7726729886834774, 'reg_alpha': 1.3696195071500525, 'reg_lambda': 12.805956093272743, 'min_child_weight': 1}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:37,435] Trial 45 finished with value: 0.0034114449448693633 and parameters: {'n_estimators': 480, 'learning_rate': 0.10056402441054291, 'max_depth': 6, 'subsample': 0.8282932994852452, 'colsample_bytree': 0.9168950502647332, 'reg_alpha': 0.42642651874423004, 'reg_lambda': 11.52413317246972, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:40,523] Trial 46 finished with value: 0.0035965383714581666 and parameters: {'n_estimators': 488, 'learning_rate': 0.10071111460282639, 'max_depth': 6, 'subsample': 0.8502005975632665, 'colsample_bytree': 0.9171751634579944, 'reg_alpha': 1.7968450074386457, 'reg_lambda': 13.354813270870727, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:43,577] Trial 47 finished with value: 0.0036168508793249596 and parameters: {'n_estimators': 479, 'learning_rate': 0.1131439776400978, 'max_depth': 6, 'subsample': 0.9793473602822009, 'colsample_bytree': 0.8848732723186639, 'reg_alpha': 0.5314100700823142, 'reg_lambda': 14.29997245634116, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:46,442] Trial 48 finished with value: 0.004690664653841102 and parameters: {'n_estimators': 510, 'learning_rate': 0.10592699491252314, 'max_depth': 6, 'subsample': 0.823930804859787, 'colsample_bytree': 0.9483013313108396, 'reg_alpha': 7.663209273081533, 'reg_lambda': 11.567863069795218, 'min_child_weight': 4}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:49,785] Trial 49 finished with value: 0.003439324448761626 and parameters: {'n_estimators': 552, 'learning_rate': 0.09508962364997563, 'max_depth': 6, 'subsample': 0.84926112986346, 'colsample_bytree': 0.9240293616819693, 'reg_alpha': 1.1209667229415938, 'reg_lambda': 12.012390234832965, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:52,273] Trial 50 finished with value: 0.0050890246888122955 and parameters: {'n_estimators': 466, 'learning_rate': 0.09540286924820929, 'max_depth': 5, 'subsample': 0.8662255265112081, 'colsample_bytree': 0.8571542797059214, 'reg_alpha': 2.6606148011557, 'reg_lambda': 12.06410941687035, 'min_child_weight': 3}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:48:57,288] Trial 51 finished with value: 0.00347441280684269 and parameters: {'n_estimators': 553, 'learning_rate': 0.08661251367419905, 'max_depth': 6, 'subsample': 0.8488900662366916, 'colsample_bytree': 0.9240833799067711, 'reg_alpha': 1.133411171068027, 'reg_lambda': 12.775744735012664, 'min_child_weight': 2}. Best is trial 40 with value: 0.0033983082638388523.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:00,940] Trial 52 finished with value: 0.0033905918012335627 and parameters: {'n_estimators': 526, 'learning_rate': 0.09839613430374873, 'max_depth': 6, 'subsample': 0.8871500437880886, 'colsample_bytree': 0.9782072214366048, 'reg_alpha': 0.5577097948220454, 'reg_lambda': 10.568320427857357, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:04,203] Trial 53 finished with value: 0.0034399771098345844 and parameters: {'n_estimators': 519, 'learning_rate': 0.09831547129783133, 'max_depth': 6, 'subsample': 0.903030660073581, 'colsample_bytree': 0.9786697801315376, 'reg_alpha': 0.4719916102186432, 'reg_lambda': 10.600815432614368, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:07,813] Trial 54 finished with value: 0.00340537374881008 and parameters: {'n_estimators': 584, 'learning_rate': 0.09172182078463738, 'max_depth': 6, 'subsample': 0.8912564876505145, 'colsample_bytree': 0.9990657044997138, 'reg_alpha': 0.923462146762776, 'reg_lambda': 9.75784425840121, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:11,578] Trial 55 finished with value: 0.003446051005629976 and parameters: {'n_estimators': 581, 'learning_rate': 0.09021390339555951, 'max_depth': 6, 'subsample': 0.9472149790472271, 'colsample_bytree': 0.9972269445473615, 'reg_alpha': 0.5394059253425406, 'reg_lambda': 9.663517693223403, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:15,304] Trial 56 finished with value: 0.003462406215080816 and parameters: {'n_estimators': 598, 'learning_rate': 0.0836977809140873, 'max_depth': 6, 'subsample': 0.9246244436375306, 'colsample_bytree': 0.9651938348248148, 'reg_alpha': 1.8521695594119836, 'reg_lambda': 9.228322731698874, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:18,584] Trial 57 finished with value: 0.0034416966223442115 and parameters: {'n_estimators': 531, 'learning_rate': 0.09192899249905614, 'max_depth': 6, 'subsample': 0.8858007910376516, 'colsample_bytree': 0.9864984457736939, 'reg_alpha': 0.36552199936193225, 'reg_lambda': 10.13987429483032, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:21,119] Trial 58 finished with value: 0.0035356044641632264 and parameters: {'n_estimators': 402, 'learning_rate': 0.11705772749355745, 'max_depth': 6, 'subsample': 0.8997821106318153, 'colsample_bytree': 0.9994163394350136, 'reg_alpha': 0.8757355124534835, 'reg_lambda': 10.621610713675743, 'min_child_weight': 2}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:24,117] Trial 59 finished with value: 0.003738532213681684 and parameters: {'n_estimators': 475, 'learning_rate': 0.10188833223537923, 'max_depth': 6, 'subsample': 0.8671349687695485, 'colsample_bytree': 0.9784187926679838, 'reg_alpha': 2.5994292068930362, 'reg_lambda': 9.909538554790338, 'min_child_weight': 1}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:28,959] Trial 60 finished with value: 0.0035506384271353046 and parameters: {'n_estimators': 504, 'learning_rate': 0.10902945932367598, 'max_depth': 6, 'subsample': 0.9145490808248192, 'colsample_bytree': 0.9605521802973374, 'reg_alpha': 1.8882971931461086, 'reg_lambda': 11.387513594561627, 'min_child_weight': 3}. Best is trial 52 with value: 0.0033905918012335627.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:32,602] Trial 61 finished with value: 0.00333748575410278 and parameters: {'n_estimators': 561, 'learning_rate': 0.09673051246597925, 'max_depth': 6, 'subsample': 0.8410311328303441, 'colsample_bytree': 0.9848666057049944, 'reg_alpha': 1.0606468805725275, 'reg_lambda': 12.125893589643004, 'min_child_weight': 2}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:35,378] Trial 62 finished with value: 0.003576934416272585 and parameters: {'n_estimators': 448, 'learning_rate': 0.08244522412495384, 'max_depth': 6, 'subsample': 0.8909085274831012, 'colsample_bytree': 0.9855904206319407, 'reg_alpha': 0.7981968843155105, 'reg_lambda': 10.786997974024786, 'min_child_weight': 2}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:38,416] Trial 63 finished with value: 0.005087637636912173 and parameters: {'n_estimators': 586, 'learning_rate': 0.08760997114415688, 'max_depth': 6, 'subsample': 0.8586734691451818, 'colsample_bytree': 0.9682969851212081, 'reg_alpha': 9.690150693820012, 'reg_lambda': 10.180443958537275, 'min_child_weight': 1}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:41,663] Trial 64 finished with value: 0.004212994179320701 and parameters: {'n_estimators': 528, 'learning_rate': 0.09781180948760108, 'max_depth': 6, 'subsample': 0.878185961111853, 'colsample_bytree': 0.9913092955308154, 'reg_alpha': 5.224470635685087, 'reg_lambda': 10.358097738203012, 'min_child_weight': 2}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:45,111] Trial 65 finished with value: 0.0034539848598514854 and parameters: {'n_estimators': 563, 'learning_rate': 0.09242851787375235, 'max_depth': 6, 'subsample': 0.9479870139359151, 'colsample_bytree': 0.9540848711211194, 'reg_alpha': 0.2696936033036583, 'reg_lambda': 11.846113557615418, 'min_child_weight': 1}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:48,571] Trial 66 finished with value: 0.0034635083083184364 and parameters: {'n_estimators': 540, 'learning_rate': 0.10261062337437463, 'max_depth': 6, 'subsample': 0.7134637340876615, 'colsample_bytree': 0.9737601551001767, 'reg_alpha': 1.240899033121535, 'reg_lambda': 11.112675900858827, 'min_child_weight': 2}. Best is trial 61 with value: 0.00333748575410278.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:52,172] Trial 67 finished with value: 0.0032918910679182174 and parameters: {'n_estimators': 565, 'learning_rate': 0.11401328040443184, 'max_depth': 6, 'subsample': 0.829003590766519, 'colsample_bytree': 0.9801877919848029, 'reg_alpha': 0.41134835862747154, 'reg_lambda': 11.482010392526005, 'min_child_weight': 3}. Best is trial 67 with value: 0.0032918910679182174.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:49:55,765] Trial 68 finished with value: 0.003290853822383524 and parameters: {'n_estimators': 599, 'learning_rate': 0.11375527068033271, 'max_depth': 6, 'subsample': 0.8371060046975172, 'colsample_bytree': 0.981385231879945, 'reg_alpha': 0.4015634567548551, 'reg_lambda': 12.283612023901101, 'min_child_weight': 4}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:01,111] Trial 69 finished with value: 0.00341801190417956 and parameters: {'n_estimators': 600, 'learning_rate': 0.12054909951897258, 'max_depth': 6, 'subsample': 0.8075089707068084, 'colsample_bytree': 0.9814529794084561, 'reg_alpha': 2.0218472494071618, 'reg_lambda': 12.499739596622053, 'min_child_weight': 4}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:04,828] Trial 70 finished with value: 0.0034090091335432127 and parameters: {'n_estimators': 581, 'learning_rate': 0.11432014140382897, 'max_depth': 6, 'subsample': 0.8411104603266049, 'colsample_bytree': 0.9613275644997278, 'reg_alpha': 1.4351842898400882, 'reg_lambda': 12.274650204507457, 'min_child_weight': 4}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:08,517] Trial 71 finished with value: 0.003356296400871711 and parameters: {'n_estimators': 581, 'learning_rate': 0.11372620986628637, 'max_depth': 6, 'subsample': 0.8381813571304556, 'colsample_bytree': 0.9602329341393794, 'reg_alpha': 1.453808255523208, 'reg_lambda': 12.291711387084973, 'min_child_weight': 5}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:12,199] Trial 72 finished with value: 0.003789821421728469 and parameters: {'n_estimators': 585, 'learning_rate': 0.1291795091291844, 'max_depth': 6, 'subsample': 0.8409742877825526, 'colsample_bytree': 0.9647621673235992, 'reg_alpha': 3.5099572556867873, 'reg_lambda': 13.36635463528811, 'min_child_weight': 5}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:15,787] Trial 73 finished with value: 0.0034404296559836056 and parameters: {'n_estimators': 574, 'learning_rate': 0.11294578772938069, 'max_depth': 6, 'subsample': 0.8388175360986144, 'colsample_bytree': 0.9892275281965328, 'reg_alpha': 1.411732363240783, 'reg_lambda': 12.259500630734081, 'min_child_weight': 5}. Best is trial 68 with value: 0.003290853822383524.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-03-03 08:50:19,671] Trial 74 finished with value: 0.0032809445414841887 and parameters: {'n_estimators': 589, 'learning_rate': 0.12005930969503895, 'max_depth': 6, 'subsample': 0.8556816841827655, 'colsample_bytree': 0.958148829739241, 'reg_alpha': 0.9929076578602127, 'reg_lambda': 12.249865929878183, 'min_child_weight': 4}. Best is trial 74 with value: 0.0032809445414841887.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_estimators': 589, 'learning_rate': 0.12005930969503895, 'max_depth': 6, 'subsample': 0.8556816841827655, 'colsample_bytree': 0.958148829739241, 'reg_alpha': 0.9929076578602127, 'reg_lambda': 12.249865929878183, 'min_child_weight': 4}\n",
      "The file 'submission_w.csv' was created successfully!\n",
      "Mean Squared Error on Training Set: 0.0014\n",
      "Mean Squared Error on Test Set: 0.0032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "\n",
    "# Define feature columns (all '_diff' columns) and target variable ('WinProbability')\n",
    "feature_columns = [col for col in pairs_df_w.columns if col.endswith('_diff')]\n",
    "XW = pairs_df_w[feature_columns]\n",
    "yw = pairs_df_w['WinProbability']\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) ensuring reproducibility\n",
    "XW_train, XW_test, yw_train, yw_test = train_test_split(XW, yw, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values using SimpleImputer (replace NaNs with the median)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "XW_train = imputer.fit_transform(XW_train)\n",
    "XW_test = imputer.transform(XW_test)\n",
    "\n",
    "print(f\"Training set size: {XW_train.shape}, Testing set size: {XW_test.shape}\")\n",
    "\n",
    "# Define the Optuna optimization function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),  # Reduced for stability\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 6),  # Reduced complexity\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),  # Increased for better generalization\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),  # Increased for better generalization\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 7.0, 15.0),  # Increased L2 regularization to reduce overfitting\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # Added to prevent overfitting\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train the model with early stopping to prevent overfitting\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(XW_train, yw_train, eval_set=[(XW_test, yw_test)], early_stopping_rounds=30, verbose=False)\n",
    "    \n",
    "    # Make predictions and clip values between 0 and 1\n",
    "    yw_pred = np.clip(model.predict(XW_test), 0, 1)\n",
    "    \n",
    "    # Return Mean Squared Error (MSE) for evaluation\n",
    "    return mean_squared_error(yw_test, yw_pred)\n",
    "\n",
    "# Run Optuna to optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=75)  # Increased trials for better optimization\n",
    "\n",
    "# Retrieve the best hyperparameters found by Optuna\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "\n",
    "# Train the final model with optimized hyperparameters and early stopping\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(XW_train, yw_train, eval_set=[(XW_test, yw_test)], early_stopping_rounds=30, verbose=False)\n",
    "\n",
    "# Generate final predictions and ensure values are between 0 and 1\n",
    "yw_pred_full = np.clip(best_model.predict(XW), 0, 1)\n",
    "pairs_df_w['WinProbability'] = yw_pred_full\n",
    "\n",
    "# Format output to match the required submission format\n",
    "season = 2025  # Adjust the season as needed\n",
    "pairs_df_w['ID'] = pairs_df_w.apply(lambda row: f\"{season}_{int(row['TeamID1'])}_{int(row['TeamID2'])}\", axis=1)\n",
    "pairs_df_w['Pred'] = pairs_df_w['WinProbability'].round(1)  # Round probabilities to one decimal place\n",
    "submission_df_w = pairs_df_w[['ID', 'Pred']]\n",
    "\n",
    "# Save the submission file\n",
    "submission_df_w.to_csv(\"/kaggle/working/submission_w.csv\", index=False)\n",
    "print(\"The file 'submission_w.csv' was created successfully!\")\n",
    "\n",
    "# Calculate and display MSE on both training and test sets\n",
    "yw_pred_train = np.clip(best_model.predict(XW_train), 0, 1)\n",
    "yw_pred_test = np.clip(best_model.predict(XW_test), 0, 1)\n",
    "train_mse = mean_squared_error(yw_train, yw_pred_train)\n",
    "test_mse = mean_squared_error(yw_test, yw_pred_test)\n",
    "print(f\"Mean Squared Error on Training Set: {train_mse:.4f}\")\n",
    "print(f\"Mean Squared Error on Test Set: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01fd7b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:24.720914Z",
     "iopub.status.busy": "2025-03-03T08:50:24.720507Z",
     "iopub.status.idle": "2025-03-03T08:50:24.770197Z",
     "shell.execute_reply": "2025-03-03T08:50:24.768885Z"
    },
    "papermill": {
     "duration": 0.084321,
     "end_time": "2025-03-03T08:50:24.772441",
     "exception": false,
     "start_time": "2025-03-03T08:50:24.688120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_3101_3102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_3101_3103</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_3101_3104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_3101_3105</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_3101_3106</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64975</th>\n",
       "      <td>2025_3475_3477</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64976</th>\n",
       "      <td>2025_3475_3478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64977</th>\n",
       "      <td>2025_3476_3477</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64978</th>\n",
       "      <td>2025_3476_3478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64979</th>\n",
       "      <td>2025_3477_3478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Pred\n",
       "0      2025_3101_3102   1.0\n",
       "1      2025_3101_3103   0.9\n",
       "2      2025_3101_3104   0.0\n",
       "3      2025_3101_3105   1.0\n",
       "4      2025_3101_3106   1.0\n",
       "...               ...   ...\n",
       "64975  2025_3475_3477   0.4\n",
       "64976  2025_3475_3478   1.0\n",
       "64977  2025_3476_3477   0.0\n",
       "64978  2025_3476_3478   1.0\n",
       "64979  2025_3477_3478   1.0\n",
       "\n",
       "[64980 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_w = pd.read_csv(\"/kaggle/working/submission_w.csv\") \n",
    "submission_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83e819",
   "metadata": {
    "papermill": {
     "duration": 0.031281,
     "end_time": "2025-03-03T08:50:24.835730",
     "exception": false,
     "start_time": "2025-03-03T08:50:24.804449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ensure that there are no empty values in the prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "914f9c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:24.902346Z",
     "iopub.status.busy": "2025-03-03T08:50:24.901963Z",
     "iopub.status.idle": "2025-03-03T08:50:25.193423Z",
     "shell.execute_reply": "2025-03-03T08:50:25.191990Z"
    },
    "papermill": {
     "duration": 0.327146,
     "end_time": "2025-03-03T08:50:25.195458",
     "exception": false,
     "start_time": "2025-03-03T08:50:24.868312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty values ​​in ID: 0\n",
      "Number of empty values ​​in TeamID1: 0\n",
      "Number of empty values ​​in TeamID2: 0\n",
      "\n",
      "There are no empty values ​​in ID, TeamID1, or TeamID2.\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "submission_w = pd.read_csv('submission_w.csv')\n",
    "\n",
    "# Check for blank values ​​in ID column\n",
    "missing_id = submission_w['ID'].isna().sum()\n",
    "print(f\"Number of empty values ​​in ID: {missing_id}\")\n",
    "\n",
    "# Extract TeamID1 and TeamID2 from ID\n",
    "submission_w[['Season', 'TeamID1', 'TeamID2']] = submission_w['ID'].str.split('_', expand=True)\n",
    "\n",
    "# Check for empty values ​​in TeamID1 and TeamID2\n",
    "missing_teamid1 = submission_w['TeamID1'].isna().sum()\n",
    "missing_teamid2 = submission_w['TeamID2'].isna().sum()\n",
    "\n",
    "print(f\"Number of empty values ​​in TeamID1: {missing_teamid1}\")\n",
    "print(f\"Number of empty values ​​in TeamID2: {missing_teamid2}\")\n",
    "\n",
    "# If there are no empty values\n",
    "if missing_id == 0 and missing_teamid1 == 0 and missing_teamid2 == 0:\n",
    "    print(\"\\nThere are no empty values ​​in ID, TeamID1, or TeamID2.\")\n",
    "else:\n",
    "    print(\"\\nThere are blank values ​​in some columns, check the data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21074ed9",
   "metadata": {
    "papermill": {
     "duration": 0.034362,
     "end_time": "2025-03-03T08:50:25.262413",
     "exception": false,
     "start_time": "2025-03-03T08:50:25.228051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stage 3: Merge the prediction models for men's and women's teams into one prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b16533f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:25.328102Z",
     "iopub.status.busy": "2025-03-03T08:50:25.327596Z",
     "iopub.status.idle": "2025-03-03T08:50:25.895029Z",
     "shell.execute_reply": "2025-03-03T08:50:25.893722Z"
    },
    "papermill": {
     "duration": 0.601453,
     "end_time": "2025-03-03T08:50:25.896835",
     "exception": false,
     "start_time": "2025-03-03T08:50:25.295382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved at: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the reference submission file (to maintain the original order)\n",
    "submission_stage2_path = \"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\"\n",
    "submission_m_path = \"submission_m.csv\"\n",
    "submission_w_path = \"submission_w.csv\"\n",
    "\n",
    "submission_stage2 = pd.read_csv(submission_stage2_path)\n",
    "submission_m = pd.read_csv(submission_m_path)\n",
    "submission_w = pd.read_csv(submission_w_path)\n",
    "\n",
    "# Convert predictions into dictionaries for fast lookup\n",
    "predictions_m = dict(zip(submission_m[\"ID\"], submission_m[\"Pred\"]))\n",
    "predictions_w = dict(zip(submission_w[\"ID\"], submission_w[\"Pred\"]))\n",
    "\n",
    "# Update predictions in the original file, keeping the same order\n",
    "submission_stage2[\"Pred\"] = submission_stage2[\"ID\"].map(lambda x: predictions_m.get(x, predictions_w.get(x, 0.5)))\n",
    "\n",
    "# Keep only the required columns: 'ID' and 'Pred'\n",
    "submission_stage2 = submission_stage2[['ID', 'Pred']]\n",
    "\n",
    "# Save the final merged submission file\n",
    "submission = \"/kaggle/working/submission.csv\"\n",
    "submission_stage2.to_csv(submission, index=False)\n",
    "\n",
    "print(f\"Submission file saved at: {submission}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ca637",
   "metadata": {
    "papermill": {
     "duration": 0.030468,
     "end_time": "2025-03-03T08:50:25.958277",
     "exception": false,
     "start_time": "2025-03-03T08:50:25.927809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensure that there are no empty values ​​in the built-in prediction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25df5487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:26.021874Z",
     "iopub.status.busy": "2025-03-03T08:50:26.021401Z",
     "iopub.status.idle": "2025-03-03T08:50:26.650737Z",
     "shell.execute_reply": "2025-03-03T08:50:26.649274Z"
    },
    "papermill": {
     "duration": 0.663442,
     "end_time": "2025-03-03T08:50:26.652794",
     "exception": false,
     "start_time": "2025-03-03T08:50:25.989352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty values ​​in columns:\n",
      "TeamID1    0\n",
      "TeamID2    0\n",
      "dtype: int64\n",
      "\n",
      "There are no empty values ​​in TeamID1 or TeamID2.\n"
     ]
    }
   ],
   "source": [
    "# Download the resulting file\n",
    "submission = pd.read_csv('/kaggle/working/submission.csv')\n",
    "\n",
    "# Ensure that the ID column exists.\n",
    "if 'ID' in submission.columns:\n",
    "    # Split ID column to extract TeamID1 and TeamID2\n",
    "    submission[['Season', 'TeamID1', 'TeamID2']] = submission['ID'].str.split('_', expand=True)\n",
    "\n",
    "    # Convert TeamID1 and TeamID2 to integers\n",
    "    submission['TeamID1'] = pd.to_numeric(submission['TeamID1'], errors='coerce')\n",
    "    submission['TeamID2'] = pd.to_numeric(submission['TeamID2'], errors='coerce')\n",
    "\n",
    "    # Find any empty values.\n",
    "    missing_values = submission[['TeamID1', 'TeamID2']].isna().sum()\n",
    "\n",
    "    print(\"Empty values ​​in columns:\")\n",
    "    print(missing_values)\n",
    "\n",
    "    # Check if there are any rows with empty values.\n",
    "    if missing_values.sum() == 0:\n",
    "        print(\"\\nThere are no empty values ​​in TeamID1 or TeamID2.\")\n",
    "    else:\n",
    "        print(\"\\nThere are empty values ​​in TeamID1 or TeamID2, please check the data.\")\n",
    "\n",
    "else:\n",
    "    print(\"Column 'ID' is missing from the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a6e4d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:26.715775Z",
     "iopub.status.busy": "2025-03-03T08:50:26.715387Z",
     "iopub.status.idle": "2025-03-03T08:50:26.830017Z",
     "shell.execute_reply": "2025-03-03T08:50:26.828304Z"
    },
    "papermill": {
     "duration": 0.148887,
     "end_time": "2025-03-03T08:50:26.832185",
     "exception": false,
     "start_time": "2025-03-03T08:50:26.683298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131407 entries, 0 to 131406\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   ID      131407 non-null  object \n",
      " 1   Pred    131407 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the saved submission file\n",
    "submission = pd.read_csv(\"/kaggle/working/submission.csv\")\n",
    "\n",
    "# Check the info of the submission DataFrame\n",
    "submission.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5af23357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:26.898259Z",
     "iopub.status.busy": "2025-03-03T08:50:26.897819Z",
     "iopub.status.idle": "2025-03-03T08:50:27.009217Z",
     "shell.execute_reply": "2025-03-03T08:50:27.007541Z"
    },
    "papermill": {
     "duration": 0.146654,
     "end_time": "2025-03-03T08:50:27.011271",
     "exception": false,
     "start_time": "2025-03-03T08:50:26.864617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131407 entries, 0 to 131406\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   ID      131407 non-null  object \n",
      " 1   Pred    131407 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "SampleSubmissionStage2 = pd.read_csv(\"/kaggle/input/march-machine-learning-mania-2025/SampleSubmissionStage2.csv\")\n",
    "SampleSubmissionStage2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07940f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T08:50:27.076088Z",
     "iopub.status.busy": "2025-03-03T08:50:27.075610Z",
     "iopub.status.idle": "2025-03-03T08:50:27.088231Z",
     "shell.execute_reply": "2025-03-03T08:50:27.086999Z"
    },
    "papermill": {
     "duration": 0.047131,
     "end_time": "2025-03-03T08:50:27.090125",
     "exception": false,
     "start_time": "2025-03-03T08:50:27.042994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131402</th>\n",
       "      <td>2025_3477_3479</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131403</th>\n",
       "      <td>2025_3477_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131404</th>\n",
       "      <td>2025_3478_3479</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131405</th>\n",
       "      <td>2025_3478_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>2025_3479_3480</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Pred\n",
       "0       2025_1101_1102   0.0\n",
       "1       2025_1101_1103   0.0\n",
       "2       2025_1101_1104   0.0\n",
       "3       2025_1101_1105   0.1\n",
       "4       2025_1101_1106   0.0\n",
       "...                ...   ...\n",
       "131402  2025_3477_3479   0.5\n",
       "131403  2025_3477_3480   0.5\n",
       "131404  2025_3478_3479   0.5\n",
       "131405  2025_3478_3480   0.5\n",
       "131406  2025_3479_3480   0.5\n",
       "\n",
       "[131407 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11165145,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 623.294717,
   "end_time": "2025-03-03T08:50:28.046468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-03T08:40:04.751751",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
